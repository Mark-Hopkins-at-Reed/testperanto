learn_bpe.py on /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/data/train.en-de...
apply_bpe.py to train.en...
apply_bpe.py to dev.en...
apply_bpe.py to test.en...
apply_bpe.py to train.de...
apply_bpe.py to dev.de...
apply_bpe.py to test.de...
2023-11-04 10:14:17 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/tensorboard_logs/', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1000, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 40, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir='/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/tensorboard_logs/', wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='chrf', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_iwslt_de_en', max_epoch=1000, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=40, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/data-bin', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_attention_heads=4, encoder_layers=6, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_iwslt_de_en'), 'task': {'_name': 'translation', 'data': '/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'chrf'}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-11-04 10:14:17 | INFO | fairseq.tasks.translation | [en] dictionary: 1248 types
2023-11-04 10:14:17 | INFO | fairseq.tasks.translation | [de] dictionary: 1264 types
2023-11-04 10:14:18 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(1248, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(1264, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=1264, bias=False)
  )
)
2023-11-04 10:14:18 | INFO | fairseq_cli.train | task: TranslationTask
2023-11-04 10:14:18 | INFO | fairseq_cli.train | model: TransformerModel
2023-11-04 10:14:18 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2023-11-04 10:14:18 | INFO | fairseq_cli.train | num. shared model params: 45,433,856 (num. trained: 45,433,856)
2023-11-04 10:14:18 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-11-04 10:14:18 | INFO | fairseq.data.data_utils | loaded 100 examples from: /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/data-bin/valid.en-de.en
2023-11-04 10:14:18 | INFO | fairseq.data.data_utils | loaded 100 examples from: /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/data-bin/valid.en-de.de
2023-11-04 10:14:18 | INFO | fairseq.tasks.translation | /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/data-bin valid en-de 100 examples
2023-11-04 10:14:20 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2023-11-04 10:14:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-11-04 10:14:20 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 47.544 GB ; name = NVIDIA RTX A6000                        
2023-11-04 10:14:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-11-04 10:14:20 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2023-11-04 10:14:20 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None
2023-11-04 10:14:20 | INFO | fairseq.trainer | Preparing to load checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:14:20 | INFO | fairseq.trainer | No existing checkpoint found /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:14:20 | INFO | fairseq.trainer | loading train data for epoch 1
2023-11-04 10:14:20 | INFO | fairseq.data.data_utils | loaded 800 examples from: /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/data-bin/train.en-de.en
2023-11-04 10:14:20 | INFO | fairseq.data.data_utils | loaded 800 examples from: /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/data-bin/train.en-de.de
2023-11-04 10:14:20 | INFO | fairseq.tasks.translation | /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/data-bin train en-de 800 examples
2023-11-04 10:14:20 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2023-11-04 10:14:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:20 | INFO | fairseq.trainer | begin training epoch 1
2023-11-04 10:14:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:22 | INFO | fairseq.tasks.translation | example hypothesis: fofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofi
2023-11-04 10:14:22 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:23 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluheluhelulaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglo
2023-11-04 10:14:23 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:23 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.428 | nll_loss 11.474 | ppl 2845.12 | bleu 0 | wps 241.4 | wpb 563 | bsz 50 | num_updates 3
2023-11-04 10:14:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 3 updates
2023-11-04 10:14:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 1 @ 3 updates, score 0.0) (writing took 1.2771996036171913 seconds)
2023-11-04 10:14:24 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-11-04 10:14:24 | INFO | train | epoch 001 | loss 11.339 | nll_loss 11.375 | ppl 2655.42 | wps 2096.2 | ups 0.81 | wpb 2567.7 | bsz 266.7 | num_updates 3 | lr 3.75e-07 | gnorm 8.274 | train_wall 1 | gb_free 45.8 | wall 4
2023-11-04 10:14:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:24 | INFO | fairseq.trainer | begin training epoch 2
2023-11-04 10:14:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:25 | INFO | fairseq.tasks.translation | example hypothesis: fofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofi
2023-11-04 10:14:25 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:25 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluheluhelulaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglo
2023-11-04 10:14:25 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:25 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.376 | nll_loss 11.417 | ppl 2734.76 | bleu 0 | wps 239.8 | wpb 563 | bsz 50 | num_updates 6 | best_bleu 0
2023-11-04 10:14:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 6 updates
2023-11-04 10:14:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 2 @ 6 updates, score 0.0) (writing took 1.7469951212406158 seconds)
2023-11-04 10:14:27 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-11-04 10:14:27 | INFO | train | epoch 002 | loss 11.313 | nll_loss 11.345 | ppl 2601.75 | wps 2507.7 | ups 0.98 | wpb 2567.7 | bsz 266.7 | num_updates 6 | lr 7.5e-07 | gnorm 8.297 | train_wall 0 | gb_free 45.9 | wall 7
2023-11-04 10:14:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:27 | INFO | fairseq.trainer | begin training epoch 3
2023-11-04 10:14:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:28 | INFO | fairseq.tasks.translation | example hypothesis: momimomimomimomimomimomimomimomimomimomilocolocolocolocolocolocolocolocolocolocolocolocolocolocolocolocolocolocolocolocolocoloco
2023-11-04 10:14:28 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:29 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluheluhelulaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglo
2023-11-04 10:14:29 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:29 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.286 | nll_loss 11.317 | ppl 2551.65 | bleu 0 | wps 182.2 | wpb 563 | bsz 50 | num_updates 9 | best_bleu 0
2023-11-04 10:14:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 9 updates
2023-11-04 10:14:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 3 @ 9 updates, score 0.0) (writing took 1.7228100802749395 seconds)
2023-11-04 10:14:30 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-11-04 10:14:30 | INFO | train | epoch 003 | loss 11.258 | nll_loss 11.284 | ppl 2494.43 | wps 2424.5 | ups 0.94 | wpb 2567.7 | bsz 266.7 | num_updates 9 | lr 1.125e-06 | gnorm 8.255 | train_wall 0 | gb_free 45.9 | wall 10
2023-11-04 10:14:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:30 | INFO | fairseq.trainer | begin training epoch 4
2023-11-04 10:14:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:31 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluheluhelualalualalualalualalualalualalufofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofi
2023-11-04 10:14:31 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:32 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluheluheluhelulaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglo
2023-11-04 10:14:32 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:32 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.157 | nll_loss 11.174 | ppl 2311.1 | bleu 0 | wps 184.3 | wpb 563 | bsz 50 | num_updates 12 | best_bleu 0
2023-11-04 10:14:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 12 updates
2023-11-04 10:14:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 4 @ 12 updates, score 0.0) (writing took 1.6453699339181185 seconds)
2023-11-04 10:14:33 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-11-04 10:14:33 | INFO | train | epoch 004 | loss 11.167 | nll_loss 11.184 | ppl 2326.09 | wps 2531.4 | ups 0.99 | wpb 2567.7 | bsz 266.7 | num_updates 12 | lr 1.5e-06 | gnorm 8.304 | train_wall 0 | gb_free 45.9 | wall 13
2023-11-04 10:14:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:33 | INFO | fairseq.trainer | begin training epoch 5
2023-11-04 10:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:34 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluheluhelualalualalualalualalualalufofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofi
2023-11-04 10:14:34 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:35 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluheluheluheluheluheluheluheluheluheluheluhelulaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglolaglo
2023-11-04 10:14:35 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:35 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.99 | nll_loss 10.989 | ppl 2032.79 | bleu 0 | wps 166.1 | wpb 563 | bsz 50 | num_updates 15 | best_bleu 0
2023-11-04 10:14:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 15 updates
2023-11-04 10:14:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 5 @ 15 updates, score 0.0) (writing took 1.650858100503683 seconds)
2023-11-04 10:14:36 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-11-04 10:14:36 | INFO | train | epoch 005 | loss 11.066 | nll_loss 11.072 | ppl 2153.16 | wps 2483.7 | ups 0.97 | wpb 2567.7 | bsz 266.7 | num_updates 15 | lr 1.875e-06 | gnorm 8.29 | train_wall 0 | gb_free 45.9 | wall 16
2023-11-04 10:14:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:36 | INFO | fairseq.trainer | begin training epoch 6
2023-11-04 10:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:37 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluhelualalualalualalualalualalufofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofi
2023-11-04 10:14:37 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:38 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluhelulocolocolocolocolocolocolocolocolocolocolocolocolocolocolocolocoloco
2023-11-04 10:14:38 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:38 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.788 | nll_loss 10.765 | ppl 1740.22 | bleu 0 | wps 169 | wpb 563 | bsz 50 | num_updates 18 | best_bleu 0
2023-11-04 10:14:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 18 updates
2023-11-04 10:14:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 6 @ 18 updates, score 0.0) (writing took 1.6435413174331188 seconds)
2023-11-04 10:14:39 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-11-04 10:14:39 | INFO | train | epoch 006 | loss 10.927 | nll_loss 10.918 | ppl 1934.48 | wps 2502.3 | ups 0.97 | wpb 2567.7 | bsz 266.7 | num_updates 18 | lr 2.25e-06 | gnorm 8.267 | train_wall 0 | gb_free 45.8 | wall 19
2023-11-04 10:14:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:39 | INFO | fairseq.trainer | begin training epoch 7
2023-11-04 10:14:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:40 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluhelualalualalualalualalualalualalualalualalualalufofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofifofi
2023-11-04 10:14:40 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:41 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluheluhelu
2023-11-04 10:14:41 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:41 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.559 | nll_loss 10.51 | ppl 1458.38 | bleu 0 | wps 162.7 | wpb 563 | bsz 50 | num_updates 21 | best_bleu 0
2023-11-04 10:14:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 21 updates
2023-11-04 10:14:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 7 @ 21 updates, score 0.0) (writing took 1.642223870381713 seconds)
2023-11-04 10:14:43 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-11-04 10:14:43 | INFO | train | epoch 007 | loss 10.754 | nll_loss 10.725 | ppl 1692.53 | wps 2484.5 | ups 0.97 | wpb 2567.7 | bsz 266.7 | num_updates 21 | lr 2.625e-06 | gnorm 8.139 | train_wall 0 | gb_free 45.8 | wall 22
2023-11-04 10:14:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:43 | INFO | fairseq.trainer | begin training epoch 8
2023-11-04 10:14:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:44 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluhelulocolocolocolocolocolocolocofofifofifofifofifofifofifofifofifofifofifofifofi
2023-11-04 10:14:44 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:44 | INFO | fairseq.tasks.translation | example hypothesis: heluheluheluheluheluhelu
2023-11-04 10:14:44 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:44 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.318 | nll_loss 10.241 | ppl 1210.21 | bleu 0.12 | wps 184.7 | wpb 563 | bsz 50 | num_updates 24 | best_bleu 0.12
2023-11-04 10:14:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 24 updates
2023-11-04 10:14:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 8 @ 24 updates, score 0.12) (writing took 1.7619992960244417 seconds)
2023-11-04 10:14:46 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-11-04 10:14:46 | INFO | train | epoch 008 | loss 10.564 | nll_loss 10.514 | ppl 1462.77 | wps 2346.3 | ups 0.91 | wpb 2567.7 | bsz 266.7 | num_updates 24 | lr 3e-06 | gnorm 7.897 | train_wall 0 | gb_free 45.9 | wall 26
2023-11-04 10:14:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:46 | INFO | fairseq.trainer | begin training epoch 9
2023-11-04 10:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:47 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:14:47 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:47 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:14:47 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:47 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.095 | nll_loss 9.988 | ppl 1015.68 | bleu 0.34 | wps 951.9 | wpb 563 | bsz 50 | num_updates 27 | best_bleu 0.34
2023-11-04 10:14:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 27 updates
2023-11-04 10:14:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 9 @ 27 updates, score 0.34) (writing took 1.6792527996003628 seconds)
2023-11-04 10:14:49 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-11-04 10:14:49 | INFO | train | epoch 009 | loss 10.359 | nll_loss 10.287 | ppl 1248.98 | wps 2675.7 | ups 1.04 | wpb 2567.7 | bsz 266.7 | num_updates 27 | lr 3.375e-06 | gnorm 7.426 | train_wall 0 | gb_free 45.8 | wall 28
2023-11-04 10:14:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:49 | INFO | fairseq.trainer | begin training epoch 10
2023-11-04 10:14:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:50 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:14:50 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:50 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:14:50 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:50 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.934 | nll_loss 9.796 | ppl 889.24 | bleu 0.51 | wps 949.1 | wpb 563 | bsz 50 | num_updates 30 | best_bleu 0.51
2023-11-04 10:14:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 30 updates
2023-11-04 10:14:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 10 @ 30 updates, score 0.51) (writing took 1.6795900240540504 seconds)
2023-11-04 10:14:51 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-11-04 10:14:51 | INFO | train | epoch 010 | loss 10.14 | nll_loss 10.041 | ppl 1053.54 | wps 2966.1 | ups 1.16 | wpb 2567.7 | bsz 266.7 | num_updates 30 | lr 3.75e-06 | gnorm 6.726 | train_wall 0 | gb_free 45.8 | wall 31
2023-11-04 10:14:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:51 | INFO | fairseq.trainer | begin training epoch 11
2023-11-04 10:14:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:52 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:14:52 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:52 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:14:52 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:52 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.883 | nll_loss 9.718 | ppl 842.01 | bleu 0.52 | wps 989.6 | wpb 563 | bsz 50 | num_updates 33 | best_bleu 0.52
2023-11-04 10:14:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 33 updates
2023-11-04 10:14:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:14:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 11 @ 33 updates, score 0.52) (writing took 1.7454557679593563 seconds)
2023-11-04 10:14:54 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-11-04 10:14:54 | INFO | train | epoch 011 | loss 9.96 | nll_loss 9.837 | ppl 914.44 | wps 2910 | ups 1.13 | wpb 2567.7 | bsz 266.7 | num_updates 33 | lr 4.125e-06 | gnorm 5.769 | train_wall 0 | gb_free 45.9 | wall 34
2023-11-04 10:14:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:54 | INFO | fairseq.trainer | begin training epoch 12
2023-11-04 10:14:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:55 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:14:55 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:55 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:14:55 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:55 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.964 | nll_loss 9.773 | ppl 874.78 | bleu 0.47 | wps 1006.8 | wpb 563 | bsz 50 | num_updates 36 | best_bleu 0.52
2023-11-04 10:14:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 36 updates
2023-11-04 10:14:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:14:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:14:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 12 @ 36 updates, score 0.47) (writing took 1.1594619788229465 seconds)
2023-11-04 10:14:56 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-11-04 10:14:56 | INFO | train | epoch 012 | loss 9.794 | nll_loss 9.646 | ppl 800.94 | wps 3752 | ups 1.46 | wpb 2567.7 | bsz 266.7 | num_updates 36 | lr 4.5e-06 | gnorm 4.593 | train_wall 0 | gb_free 45.9 | wall 36
2023-11-04 10:14:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:56 | INFO | fairseq.trainer | begin training epoch 13
2023-11-04 10:14:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:57 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:14:57 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:57 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:14:57 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:57 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.1 | nll_loss 9.887 | ppl 946.94 | bleu 0.43 | wps 614.1 | wpb 563 | bsz 50 | num_updates 39 | best_bleu 0.52
2023-11-04 10:14:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 39 updates
2023-11-04 10:14:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:14:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:14:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 13 @ 39 updates, score 0.43) (writing took 1.1168834008276463 seconds)
2023-11-04 10:14:58 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-11-04 10:14:58 | INFO | train | epoch 013 | loss 9.675 | nll_loss 9.504 | ppl 725.97 | wps 3755.3 | ups 1.46 | wpb 2567.7 | bsz 266.7 | num_updates 39 | lr 4.875e-06 | gnorm 3.727 | train_wall 0 | gb_free 45.8 | wall 38
2023-11-04 10:14:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:14:58 | INFO | fairseq.trainer | begin training epoch 14
2023-11-04 10:14:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:14:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:14:59 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:14:59 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:14:59 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:14:59 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:14:59 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.146 | nll_loss 9.918 | ppl 967.15 | bleu 0.45 | wps 979.1 | wpb 563 | bsz 50 | num_updates 42 | best_bleu 0.52
2023-11-04 10:14:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 42 updates
2023-11-04 10:14:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 14 @ 42 updates, score 0.45) (writing took 1.1270297765731812 seconds)
2023-11-04 10:15:00 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-11-04 10:15:00 | INFO | train | epoch 014 | loss 9.592 | nll_loss 9.401 | ppl 675.83 | wps 4081.7 | ups 1.59 | wpb 2567.7 | bsz 266.7 | num_updates 42 | lr 5.25e-06 | gnorm 3.66 | train_wall 0 | gb_free 45.8 | wall 40
2023-11-04 10:15:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:00 | INFO | fairseq.trainer | begin training epoch 15
2023-11-04 10:15:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:01 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:01 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:01 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:01 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:01 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.05 | nll_loss 9.812 | ppl 898.68 | bleu 0.5 | wps 986.8 | wpb 563 | bsz 50 | num_updates 45 | best_bleu 0.52
2023-11-04 10:15:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 45 updates
2023-11-04 10:15:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 15 @ 45 updates, score 0.5) (writing took 1.1267689745873213 seconds)
2023-11-04 10:15:02 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-11-04 10:15:02 | INFO | train | epoch 015 | loss 9.527 | nll_loss 9.321 | ppl 639.7 | wps 3959.8 | ups 1.54 | wpb 2567.7 | bsz 266.7 | num_updates 45 | lr 5.625e-06 | gnorm 3.948 | train_wall 0 | gb_free 45.8 | wall 42
2023-11-04 10:15:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:02 | INFO | fairseq.trainer | begin training epoch 16
2023-11-04 10:15:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:03 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:15:03 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:03 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:15:03 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:03 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.859 | nll_loss 9.616 | ppl 784.89 | bleu 0.59 | wps 999.7 | wpb 563 | bsz 50 | num_updates 48 | best_bleu 0.59
2023-11-04 10:15:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 48 updates
2023-11-04 10:15:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:15:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:15:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 16 @ 48 updates, score 0.59) (writing took 1.6635402403771877 seconds)
2023-11-04 10:15:04 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-11-04 10:15:04 | INFO | train | epoch 016 | loss 9.461 | nll_loss 9.248 | ppl 608.12 | wps 3119.8 | ups 1.22 | wpb 2567.7 | bsz 266.7 | num_updates 48 | lr 6e-06 | gnorm 3.886 | train_wall 0 | gb_free 45.8 | wall 44
2023-11-04 10:15:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:04 | INFO | fairseq.trainer | begin training epoch 17
2023-11-04 10:15:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:05 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:15:05 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:05 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:15:05 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:05 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.622 | nll_loss 9.378 | ppl 665.23 | bleu 0.59 | wps 988.2 | wpb 563 | bsz 50 | num_updates 51 | best_bleu 0.59
2023-11-04 10:15:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 51 updates
2023-11-04 10:15:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:15:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:15:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 17 @ 51 updates, score 0.59) (writing took 1.66583183221519 seconds)
2023-11-04 10:15:07 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-11-04 10:15:07 | INFO | train | epoch 017 | loss 9.4 | nll_loss 9.186 | ppl 582.3 | wps 3046.7 | ups 1.19 | wpb 2567.7 | bsz 266.7 | num_updates 51 | lr 6.375e-06 | gnorm 3.57 | train_wall 0 | gb_free 45.9 | wall 47
2023-11-04 10:15:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:07 | INFO | fairseq.trainer | begin training epoch 18
2023-11-04 10:15:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:08 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:08 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:08 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:15:08 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:08 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.406 | nll_loss 9.163 | ppl 573.31 | bleu 0.49 | wps 990.9 | wpb 563 | bsz 50 | num_updates 54 | best_bleu 0.59
2023-11-04 10:15:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 54 updates
2023-11-04 10:15:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 18 @ 54 updates, score 0.49) (writing took 1.1525240149348974 seconds)
2023-11-04 10:15:09 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-11-04 10:15:09 | INFO | train | epoch 018 | loss 9.294 | nll_loss 9.075 | ppl 539.19 | wps 3695.1 | ups 1.44 | wpb 2567.7 | bsz 266.7 | num_updates 54 | lr 6.75e-06 | gnorm 3.08 | train_wall 1 | gb_free 45.8 | wall 49
2023-11-04 10:15:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:09 | INFO | fairseq.trainer | begin training epoch 19
2023-11-04 10:15:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:10 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:10 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:10 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:10 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:10 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.283 | nll_loss 9.038 | ppl 525.74 | bleu 0.45 | wps 990.7 | wpb 563 | bsz 50 | num_updates 57 | best_bleu 0.59
2023-11-04 10:15:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 57 updates
2023-11-04 10:15:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 19 @ 57 updates, score 0.45) (writing took 1.1983658708631992 seconds)
2023-11-04 10:15:11 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-11-04 10:15:11 | INFO | train | epoch 019 | loss 9.248 | nll_loss 9.03 | ppl 522.68 | wps 3700.3 | ups 1.44 | wpb 2567.7 | bsz 266.7 | num_updates 57 | lr 7.125e-06 | gnorm 2.701 | train_wall 0 | gb_free 45.9 | wall 51
2023-11-04 10:15:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:11 | INFO | fairseq.trainer | begin training epoch 20
2023-11-04 10:15:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:12 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:12 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:12 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:12 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:12 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.208 | nll_loss 8.959 | ppl 497.5 | bleu 0.43 | wps 956.7 | wpb 563 | bsz 50 | num_updates 60 | best_bleu 0.59
2023-11-04 10:15:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 60 updates
2023-11-04 10:15:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 20 @ 60 updates, score 0.43) (writing took 1.2281661741435528 seconds)
2023-11-04 10:15:13 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-11-04 10:15:13 | INFO | train | epoch 020 | loss 9.21 | nll_loss 8.99 | ppl 508.42 | wps 3574.4 | ups 1.39 | wpb 2567.7 | bsz 266.7 | num_updates 60 | lr 7.5e-06 | gnorm 2.813 | train_wall 0 | gb_free 45.8 | wall 53
2023-11-04 10:15:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:13 | INFO | fairseq.trainer | begin training epoch 21
2023-11-04 10:15:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:14 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:14 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:14 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:14 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:14 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.154 | nll_loss 8.898 | ppl 476.96 | bleu 0.43 | wps 965.3 | wpb 563 | bsz 50 | num_updates 63 | best_bleu 0.59
2023-11-04 10:15:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 63 updates
2023-11-04 10:15:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 21 @ 63 updates, score 0.43) (writing took 1.2221444100141525 seconds)
2023-11-04 10:15:15 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-11-04 10:15:15 | INFO | train | epoch 021 | loss 9.144 | nll_loss 8.916 | ppl 483.19 | wps 3626 | ups 1.41 | wpb 2567.7 | bsz 266.7 | num_updates 63 | lr 7.875e-06 | gnorm 2.779 | train_wall 0 | gb_free 45.8 | wall 55
2023-11-04 10:15:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:15 | INFO | fairseq.trainer | begin training epoch 22
2023-11-04 10:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:16 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:16 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:16 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:16 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:16 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.121 | nll_loss 8.855 | ppl 462.94 | bleu 0.46 | wps 906.5 | wpb 563 | bsz 50 | num_updates 66 | best_bleu 0.59
2023-11-04 10:15:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 66 updates
2023-11-04 10:15:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 22 @ 66 updates, score 0.46) (writing took 1.2546228747814894 seconds)
2023-11-04 10:15:18 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-11-04 10:15:18 | INFO | train | epoch 022 | loss 9.112 | nll_loss 8.878 | ppl 470.62 | wps 3418.8 | ups 1.33 | wpb 2567.7 | bsz 266.7 | num_updates 66 | lr 8.25e-06 | gnorm 2.639 | train_wall 1 | gb_free 45.9 | wall 57
2023-11-04 10:15:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:18 | INFO | fairseq.trainer | begin training epoch 23
2023-11-04 10:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:19 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:19 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:19 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:19 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:19 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.105 | nll_loss 8.828 | ppl 454.52 | bleu 0.48 | wps 916.2 | wpb 563 | bsz 50 | num_updates 69 | best_bleu 0.59
2023-11-04 10:15:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 69 updates
2023-11-04 10:15:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 23 @ 69 updates, score 0.48) (writing took 1.2105025555938482 seconds)
2023-11-04 10:15:20 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-11-04 10:15:20 | INFO | train | epoch 023 | loss 9.058 | nll_loss 8.815 | ppl 450.52 | wps 3540.5 | ups 1.38 | wpb 2567.7 | bsz 266.7 | num_updates 69 | lr 8.625e-06 | gnorm 2.45 | train_wall 1 | gb_free 45.9 | wall 60
2023-11-04 10:15:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:20 | INFO | fairseq.trainer | begin training epoch 24
2023-11-04 10:15:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:21 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:21 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:21 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:21 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:21 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.069 | nll_loss 8.785 | ppl 440.98 | bleu 0.47 | wps 923 | wpb 563 | bsz 50 | num_updates 72 | best_bleu 0.59
2023-11-04 10:15:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 72 updates
2023-11-04 10:15:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 24 @ 72 updates, score 0.47) (writing took 1.213410023599863 seconds)
2023-11-04 10:15:22 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-11-04 10:15:22 | INFO | train | epoch 024 | loss 9.003 | nll_loss 8.75 | ppl 430.67 | wps 3614.1 | ups 1.41 | wpb 2567.7 | bsz 266.7 | num_updates 72 | lr 9e-06 | gnorm 2.28 | train_wall 0 | gb_free 45.8 | wall 62
2023-11-04 10:15:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:22 | INFO | fairseq.trainer | begin training epoch 25
2023-11-04 10:15:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:23 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:23 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:23 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:23 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:23 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.012 | nll_loss 8.722 | ppl 422.36 | bleu 0.46 | wps 922.6 | wpb 563 | bsz 50 | num_updates 75 | best_bleu 0.59
2023-11-04 10:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 75 updates
2023-11-04 10:15:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 25 @ 75 updates, score 0.46) (writing took 1.1764188092201948 seconds)
2023-11-04 10:15:24 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-11-04 10:15:24 | INFO | train | epoch 025 | loss 8.974 | nll_loss 8.717 | ppl 420.79 | wps 3711.2 | ups 1.45 | wpb 2567.7 | bsz 266.7 | num_updates 75 | lr 9.375e-06 | gnorm 2.257 | train_wall 0 | gb_free 45.8 | wall 64
2023-11-04 10:15:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:24 | INFO | fairseq.trainer | begin training epoch 26
2023-11-04 10:15:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:25 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:25 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:25 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:25 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:25 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.936 | nll_loss 8.643 | ppl 399.76 | bleu 0.44 | wps 939.8 | wpb 563 | bsz 50 | num_updates 78 | best_bleu 0.59
2023-11-04 10:15:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 78 updates
2023-11-04 10:15:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 26 @ 78 updates, score 0.44) (writing took 1.1992845963686705 seconds)
2023-11-04 10:15:26 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-11-04 10:15:26 | INFO | train | epoch 026 | loss 8.932 | nll_loss 8.671 | ppl 407.53 | wps 3682.2 | ups 1.43 | wpb 2567.7 | bsz 266.7 | num_updates 78 | lr 9.75e-06 | gnorm 2.172 | train_wall 0 | gb_free 45.8 | wall 66
2023-11-04 10:15:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:26 | INFO | fairseq.trainer | begin training epoch 27
2023-11-04 10:15:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:27 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:27 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:27 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:27 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:27 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.864 | nll_loss 8.567 | ppl 379.26 | bleu 0.45 | wps 926.1 | wpb 563 | bsz 50 | num_updates 81 | best_bleu 0.59
2023-11-04 10:15:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 81 updates
2023-11-04 10:15:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 27 @ 81 updates, score 0.45) (writing took 1.3005636930465698 seconds)
2023-11-04 10:15:28 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-11-04 10:15:28 | INFO | train | epoch 027 | loss 8.887 | nll_loss 8.623 | ppl 394.15 | wps 3472.8 | ups 1.35 | wpb 2567.7 | bsz 266.7 | num_updates 81 | lr 1.0125e-05 | gnorm 2.074 | train_wall 0 | gb_free 45.8 | wall 68
2023-11-04 10:15:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:28 | INFO | fairseq.trainer | begin training epoch 28
2023-11-04 10:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:29 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:29 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:29 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:29 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:29 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.8 | nll_loss 8.5 | ppl 361.97 | bleu 0.46 | wps 894 | wpb 563 | bsz 50 | num_updates 84 | best_bleu 0.59
2023-11-04 10:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 84 updates
2023-11-04 10:15:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 28 @ 84 updates, score 0.46) (writing took 1.2550079971551895 seconds)
2023-11-04 10:15:31 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-11-04 10:15:31 | INFO | train | epoch 028 | loss 8.853 | nll_loss 8.586 | ppl 384.21 | wps 3449.3 | ups 1.34 | wpb 2567.7 | bsz 266.7 | num_updates 84 | lr 1.05e-05 | gnorm 2.028 | train_wall 1 | gb_free 45.8 | wall 70
2023-11-04 10:15:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:31 | INFO | fairseq.trainer | begin training epoch 29
2023-11-04 10:15:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:31 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:31 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:32 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:32 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:32 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.751 | nll_loss 8.446 | ppl 348.74 | bleu 0.46 | wps 927.3 | wpb 563 | bsz 50 | num_updates 87 | best_bleu 0.59
2023-11-04 10:15:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 87 updates
2023-11-04 10:15:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 29 @ 87 updates, score 0.46) (writing took 1.2081581950187683 seconds)
2023-11-04 10:15:33 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-11-04 10:15:33 | INFO | train | epoch 029 | loss 8.813 | nll_loss 8.543 | ppl 373.09 | wps 3550.5 | ups 1.38 | wpb 2567.7 | bsz 266.7 | num_updates 87 | lr 1.0875e-05 | gnorm 2.02 | train_wall 1 | gb_free 45.8 | wall 73
2023-11-04 10:15:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:33 | INFO | fairseq.trainer | begin training epoch 30
2023-11-04 10:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:34 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:34 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:34 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:34 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:34 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.715 | nll_loss 8.405 | ppl 338.98 | bleu 0.45 | wps 913.8 | wpb 563 | bsz 50 | num_updates 90 | best_bleu 0.59
2023-11-04 10:15:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 90 updates
2023-11-04 10:15:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 30 @ 90 updates, score 0.45) (writing took 1.2352815065532923 seconds)
2023-11-04 10:15:35 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-11-04 10:15:35 | INFO | train | epoch 030 | loss 8.791 | nll_loss 8.517 | ppl 366.44 | wps 3445.4 | ups 1.34 | wpb 2567.7 | bsz 266.7 | num_updates 90 | lr 1.125e-05 | gnorm 1.921 | train_wall 1 | gb_free 45.9 | wall 75
2023-11-04 10:15:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:35 | INFO | fairseq.trainer | begin training epoch 31
2023-11-04 10:15:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:36 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:36 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:36 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:36 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:36 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.673 | nll_loss 8.358 | ppl 328.21 | bleu 0.45 | wps 921.5 | wpb 563 | bsz 50 | num_updates 93 | best_bleu 0.59
2023-11-04 10:15:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 93 updates
2023-11-04 10:15:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 31 @ 93 updates, score 0.45) (writing took 1.286213643848896 seconds)
2023-11-04 10:15:37 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-11-04 10:15:37 | INFO | train | epoch 031 | loss 8.757 | nll_loss 8.479 | ppl 356.91 | wps 3489.2 | ups 1.36 | wpb 2567.7 | bsz 266.7 | num_updates 93 | lr 1.1625e-05 | gnorm 1.908 | train_wall 0 | gb_free 45.8 | wall 77
2023-11-04 10:15:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:37 | INFO | fairseq.trainer | begin training epoch 32
2023-11-04 10:15:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:38 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:38 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:38 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:38 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:38 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.626 | nll_loss 8.307 | ppl 316.71 | bleu 0.47 | wps 918.2 | wpb 563 | bsz 50 | num_updates 96 | best_bleu 0.59
2023-11-04 10:15:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 96 updates
2023-11-04 10:15:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 32 @ 96 updates, score 0.47) (writing took 1.2461233790963888 seconds)
2023-11-04 10:15:39 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-11-04 10:15:39 | INFO | train | epoch 032 | loss 8.715 | nll_loss 8.432 | ppl 345.47 | wps 3554.3 | ups 1.38 | wpb 2567.7 | bsz 266.7 | num_updates 96 | lr 1.2e-05 | gnorm 1.863 | train_wall 0 | gb_free 45.8 | wall 79
2023-11-04 10:15:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:39 | INFO | fairseq.trainer | begin training epoch 33
2023-11-04 10:15:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:40 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:40 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:40 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:40 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:40 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.583 | nll_loss 8.259 | ppl 306.36 | bleu 0.52 | wps 925.1 | wpb 563 | bsz 50 | num_updates 99 | best_bleu 0.59
2023-11-04 10:15:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 99 updates
2023-11-04 10:15:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 33 @ 99 updates, score 0.52) (writing took 1.235825726762414 seconds)
2023-11-04 10:15:42 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-11-04 10:15:42 | INFO | train | epoch 033 | loss 8.68 | nll_loss 8.393 | ppl 336.22 | wps 3580.3 | ups 1.39 | wpb 2567.7 | bsz 266.7 | num_updates 99 | lr 1.2375e-05 | gnorm 1.799 | train_wall 0 | gb_free 45.8 | wall 81
2023-11-04 10:15:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:42 | INFO | fairseq.trainer | begin training epoch 34
2023-11-04 10:15:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:42 | INFO | train_inner | epoch 034:      1 / 3 loss=9.675, nll_loss=9.508, ppl=728.13, wps=3165.4, ups=1.23, wpb=2567.3, bsz=267.7, num_updates=100, lr=1.25e-05, gnorm=4.396, train_wall=16, gb_free=45.8, wall=82
2023-11-04 10:15:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:42 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:42 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:43 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:43 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:43 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.544 | nll_loss 8.215 | ppl 297.24 | bleu 0.55 | wps 913.6 | wpb 563 | bsz 50 | num_updates 102 | best_bleu 0.59
2023-11-04 10:15:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 102 updates
2023-11-04 10:15:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 34 @ 102 updates, score 0.55) (writing took 1.2227009795606136 seconds)
2023-11-04 10:15:44 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-11-04 10:15:44 | INFO | train | epoch 034 | loss 8.659 | nll_loss 8.369 | ppl 330.56 | wps 3473.9 | ups 1.35 | wpb 2567.7 | bsz 266.7 | num_updates 102 | lr 1.275e-05 | gnorm 1.86 | train_wall 1 | gb_free 45.8 | wall 84
2023-11-04 10:15:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:44 | INFO | fairseq.trainer | begin training epoch 35
2023-11-04 10:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:45 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:45 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:45 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:45 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:45 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.496 | nll_loss 8.164 | ppl 286.74 | bleu 0.54 | wps 922.3 | wpb 563 | bsz 50 | num_updates 105 | best_bleu 0.59
2023-11-04 10:15:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 105 updates
2023-11-04 10:15:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 35 @ 105 updates, score 0.54) (writing took 1.244871698319912 seconds)
2023-11-04 10:15:46 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-11-04 10:15:46 | INFO | train | epoch 035 | loss 8.617 | nll_loss 8.322 | ppl 320.1 | wps 3484.1 | ups 1.36 | wpb 2567.7 | bsz 266.7 | num_updates 105 | lr 1.3125e-05 | gnorm 1.798 | train_wall 1 | gb_free 45.8 | wall 86
2023-11-04 10:15:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:46 | INFO | fairseq.trainer | begin training epoch 36
2023-11-04 10:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:47 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:47 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:47 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:15:47 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:47 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.443 | nll_loss 8.107 | ppl 275.67 | bleu 0.54 | wps 927.3 | wpb 563 | bsz 50 | num_updates 108 | best_bleu 0.59
2023-11-04 10:15:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 108 updates
2023-11-04 10:15:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 36 @ 108 updates, score 0.54) (writing took 1.1945063080638647 seconds)
2023-11-04 10:15:48 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-11-04 10:15:48 | INFO | train | epoch 036 | loss 8.591 | nll_loss 8.294 | ppl 313.95 | wps 3627.2 | ups 1.41 | wpb 2567.7 | bsz 266.7 | num_updates 108 | lr 1.35e-05 | gnorm 1.772 | train_wall 0 | gb_free 45.8 | wall 88
2023-11-04 10:15:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:48 | INFO | fairseq.trainer | begin training epoch 37
2023-11-04 10:15:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:49 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:15:49 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:49 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:15:49 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:49 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.4 | nll_loss 8.056 | ppl 266.22 | bleu 0.65 | wps 938.1 | wpb 563 | bsz 50 | num_updates 111 | best_bleu 0.65
2023-11-04 10:15:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 111 updates
2023-11-04 10:15:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:15:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:15:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 37 @ 111 updates, score 0.65) (writing took 1.7391951251775026 seconds)
2023-11-04 10:15:51 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-11-04 10:15:51 | INFO | train | epoch 037 | loss 8.561 | nll_loss 8.26 | ppl 306.57 | wps 2914.6 | ups 1.14 | wpb 2567.7 | bsz 266.7 | num_updates 111 | lr 1.3875e-05 | gnorm 1.769 | train_wall 0 | gb_free 45.8 | wall 90
2023-11-04 10:15:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:51 | INFO | fairseq.trainer | begin training epoch 38
2023-11-04 10:15:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:51 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:15:51 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:51 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:15:51 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:51 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.36 | nll_loss 8.01 | ppl 257.84 | bleu 0.74 | wps 1000.4 | wpb 563 | bsz 50 | num_updates 114 | best_bleu 0.74
2023-11-04 10:15:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 114 updates
2023-11-04 10:15:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:15:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:15:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 38 @ 114 updates, score 0.74) (writing took 1.6849364507943392 seconds)
2023-11-04 10:15:53 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-11-04 10:15:53 | INFO | train | epoch 038 | loss 8.508 | nll_loss 8.2 | ppl 294.16 | wps 3140.9 | ups 1.22 | wpb 2567.7 | bsz 266.7 | num_updates 114 | lr 1.425e-05 | gnorm 1.698 | train_wall 0 | gb_free 45.8 | wall 93
2023-11-04 10:15:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:53 | INFO | fairseq.trainer | begin training epoch 39
2023-11-04 10:15:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:54 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:15:54 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:54 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:15:54 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:54 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.314 | nll_loss 7.958 | ppl 248.59 | bleu 0.69 | wps 978 | wpb 563 | bsz 50 | num_updates 117 | best_bleu 0.74
2023-11-04 10:15:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 117 updates
2023-11-04 10:15:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 39 @ 117 updates, score 0.69) (writing took 1.1432395000010729 seconds)
2023-11-04 10:15:55 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-11-04 10:15:55 | INFO | train | epoch 039 | loss 8.475 | nll_loss 8.162 | ppl 286.35 | wps 4013.5 | ups 1.56 | wpb 2567.7 | bsz 266.7 | num_updates 117 | lr 1.4625e-05 | gnorm 1.646 | train_wall 0 | gb_free 45.9 | wall 95
2023-11-04 10:15:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:55 | INFO | fairseq.trainer | begin training epoch 40
2023-11-04 10:15:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:56 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:15:56 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:56 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:15:56 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:56 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.249 | nll_loss 7.888 | ppl 236.85 | bleu 0.63 | wps 977.2 | wpb 563 | bsz 50 | num_updates 120 | best_bleu 0.74
2023-11-04 10:15:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 120 updates
2023-11-04 10:15:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:15:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 40 @ 120 updates, score 0.63) (writing took 1.1264390964061022 seconds)
2023-11-04 10:15:57 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-11-04 10:15:57 | INFO | train | epoch 040 | loss 8.435 | nll_loss 8.117 | ppl 277.66 | wps 4000.2 | ups 1.56 | wpb 2567.7 | bsz 266.7 | num_updates 120 | lr 1.5e-05 | gnorm 1.752 | train_wall 0 | gb_free 45.8 | wall 97
2023-11-04 10:15:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:15:57 | INFO | fairseq.trainer | begin training epoch 41
2023-11-04 10:15:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:15:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:15:58 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:15:58 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:15:58 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:15:58 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:15:58 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.203 | nll_loss 7.834 | ppl 228.15 | bleu 0.74 | wps 980.5 | wpb 563 | bsz 50 | num_updates 123 | best_bleu 0.74
2023-11-04 10:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 123 updates
2023-11-04 10:15:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:15:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 41 @ 123 updates, score 0.74) (writing took 1.7430407833307981 seconds)
2023-11-04 10:16:00 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-11-04 10:16:00 | INFO | train | epoch 041 | loss 8.406 | nll_loss 8.087 | ppl 271.84 | wps 3051.8 | ups 1.19 | wpb 2567.7 | bsz 266.7 | num_updates 123 | lr 1.5375e-05 | gnorm 1.741 | train_wall 0 | gb_free 45.9 | wall 99
2023-11-04 10:16:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:00 | INFO | fairseq.trainer | begin training epoch 42
2023-11-04 10:16:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:00 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:16:00 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:00 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:16:00 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:00 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.164 | nll_loss 7.785 | ppl 220.6 | bleu 0.69 | wps 976.5 | wpb 563 | bsz 50 | num_updates 126 | best_bleu 0.74
2023-11-04 10:16:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 126 updates
2023-11-04 10:16:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 42 @ 126 updates, score 0.69) (writing took 1.1286245323717594 seconds)
2023-11-04 10:16:01 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-11-04 10:16:01 | INFO | train | epoch 042 | loss 8.367 | nll_loss 8.042 | ppl 263.47 | wps 4070.8 | ups 1.59 | wpb 2567.7 | bsz 266.7 | num_updates 126 | lr 1.575e-05 | gnorm 1.641 | train_wall 0 | gb_free 45.8 | wall 101
2023-11-04 10:16:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:01 | INFO | fairseq.trainer | begin training epoch 43
2023-11-04 10:16:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:02 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:02 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:02 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:02 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:02 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.13 | nll_loss 7.741 | ppl 214 | bleu 0.62 | wps 975.7 | wpb 563 | bsz 50 | num_updates 129 | best_bleu 0.74
2023-11-04 10:16:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 129 updates
2023-11-04 10:16:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 43 @ 129 updates, score 0.62) (writing took 1.1190387587994337 seconds)
2023-11-04 10:16:03 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-11-04 10:16:03 | INFO | train | epoch 043 | loss 8.309 | nll_loss 7.975 | ppl 251.55 | wps 4092 | ups 1.59 | wpb 2567.7 | bsz 266.7 | num_updates 129 | lr 1.6125e-05 | gnorm 1.596 | train_wall 0 | gb_free 45.8 | wall 103
2023-11-04 10:16:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:03 | INFO | fairseq.trainer | begin training epoch 44
2023-11-04 10:16:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:04 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:04 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:04 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:04 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:04 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.104 | nll_loss 7.706 | ppl 208.84 | bleu 0.54 | wps 981.6 | wpb 563 | bsz 50 | num_updates 132 | best_bleu 0.74
2023-11-04 10:16:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 132 updates
2023-11-04 10:16:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 44 @ 132 updates, score 0.54) (writing took 1.1167001444846392 seconds)
2023-11-04 10:16:05 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-11-04 10:16:05 | INFO | train | epoch 044 | loss 8.263 | nll_loss 7.922 | ppl 242.46 | wps 4069.7 | ups 1.58 | wpb 2567.7 | bsz 266.7 | num_updates 132 | lr 1.65e-05 | gnorm 1.815 | train_wall 0 | gb_free 45.9 | wall 105
2023-11-04 10:16:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:05 | INFO | fairseq.trainer | begin training epoch 45
2023-11-04 10:16:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:06 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:06 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:06 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:06 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:06 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.069 | nll_loss 7.661 | ppl 202.44 | bleu 0.47 | wps 982.7 | wpb 563 | bsz 50 | num_updates 135 | best_bleu 0.74
2023-11-04 10:16:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 135 updates
2023-11-04 10:16:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 45 @ 135 updates, score 0.47) (writing took 1.1179551482200623 seconds)
2023-11-04 10:16:07 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-11-04 10:16:07 | INFO | train | epoch 045 | loss 8.222 | nll_loss 7.874 | ppl 234.63 | wps 4029.7 | ups 1.57 | wpb 2567.7 | bsz 266.7 | num_updates 135 | lr 1.6875e-05 | gnorm 1.67 | train_wall 0 | gb_free 45.8 | wall 107
2023-11-04 10:16:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:07 | INFO | fairseq.trainer | begin training epoch 46
2023-11-04 10:16:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:08 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:08 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:08 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:08 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:08 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.03 | nll_loss 7.615 | ppl 196.09 | bleu 0.45 | wps 985.6 | wpb 563 | bsz 50 | num_updates 138 | best_bleu 0.74
2023-11-04 10:16:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 138 updates
2023-11-04 10:16:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 46 @ 138 updates, score 0.45) (writing took 1.1914847791194916 seconds)
2023-11-04 10:16:09 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-11-04 10:16:09 | INFO | train | epoch 046 | loss 8.173 | nll_loss 7.818 | ppl 225.61 | wps 3795.3 | ups 1.48 | wpb 2567.7 | bsz 266.7 | num_updates 138 | lr 1.725e-05 | gnorm 1.629 | train_wall 0 | gb_free 45.9 | wall 109
2023-11-04 10:16:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:09 | INFO | fairseq.trainer | begin training epoch 47
2023-11-04 10:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:10 | INFO | fairseq.tasks.translation | example hypothesis: the
2023-11-04 10:16:10 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:10 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:10 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:10 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.002 | nll_loss 7.579 | ppl 191.2 | bleu 0.74 | wps 898 | wpb 563 | bsz 50 | num_updates 141 | best_bleu 0.74
2023-11-04 10:16:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 141 updates
2023-11-04 10:16:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 47 @ 141 updates, score 0.74) (writing took 1.7620922960340977 seconds)
2023-11-04 10:16:12 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-11-04 10:16:12 | INFO | train | epoch 047 | loss 8.122 | nll_loss 7.759 | ppl 216.65 | wps 2751.2 | ups 1.07 | wpb 2567.7 | bsz 266.7 | num_updates 141 | lr 1.7625e-05 | gnorm 1.619 | train_wall 1 | gb_free 45.8 | wall 112
2023-11-04 10:16:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:12 | INFO | fairseq.trainer | begin training epoch 48
2023-11-04 10:16:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:13 | INFO | fairseq.tasks.translation | example hypothesis: the
2023-11-04 10:16:13 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:13 | INFO | fairseq.tasks.translation | example hypothesis: the
2023-11-04 10:16:13 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:13 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 7.978 | nll_loss 7.548 | ppl 187.2 | bleu 0.85 | wps 991.8 | wpb 563 | bsz 50 | num_updates 144 | best_bleu 0.85
2023-11-04 10:16:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 144 updates
2023-11-04 10:16:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 48 @ 144 updates, score 0.85) (writing took 1.660681003704667 seconds)
2023-11-04 10:16:15 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-11-04 10:16:15 | INFO | train | epoch 048 | loss 8.1 | nll_loss 7.732 | ppl 212.66 | wps 2917.4 | ups 1.14 | wpb 2567.7 | bsz 266.7 | num_updates 144 | lr 1.8e-05 | gnorm 1.895 | train_wall 0 | gb_free 45.9 | wall 114
2023-11-04 10:16:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:15 | INFO | fairseq.trainer | begin training epoch 49
2023-11-04 10:16:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:16 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:16 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:16 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:16 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:16 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.93 | nll_loss 7.495 | ppl 180.36 | bleu 1.1 | wps 989.8 | wpb 563 | bsz 50 | num_updates 147 | best_bleu 1.1
2023-11-04 10:16:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 147 updates
2023-11-04 10:16:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 49 @ 147 updates, score 1.1) (writing took 1.6850355416536331 seconds)
2023-11-04 10:16:17 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-11-04 10:16:17 | INFO | train | epoch 049 | loss 8.031 | nll_loss 7.656 | ppl 201.62 | wps 2899.3 | ups 1.13 | wpb 2567.7 | bsz 266.7 | num_updates 147 | lr 1.8375e-05 | gnorm 1.772 | train_wall 0 | gb_free 45.8 | wall 117
2023-11-04 10:16:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:17 | INFO | fairseq.trainer | begin training epoch 50
2023-11-04 10:16:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:18 | INFO | fairseq.tasks.translation | example hypothesis: the
2023-11-04 10:16:18 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:18 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:18 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:18 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 7.909 | nll_loss 7.465 | ppl 176.71 | bleu 0 | wps 983.6 | wpb 563 | bsz 50 | num_updates 150 | best_bleu 1.1
2023-11-04 10:16:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 150 updates
2023-11-04 10:16:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 50 @ 150 updates, score 0.0) (writing took 1.1222746204584837 seconds)
2023-11-04 10:16:19 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-11-04 10:16:19 | INFO | train | epoch 050 | loss 8.008 | nll_loss 7.627 | ppl 197.62 | wps 3691.3 | ups 1.44 | wpb 2567.7 | bsz 266.7 | num_updates 150 | lr 1.875e-05 | gnorm 1.697 | train_wall 0 | gb_free 45.9 | wall 119
2023-11-04 10:16:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:19 | INFO | fairseq.trainer | begin training epoch 51
2023-11-04 10:16:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:20 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:20 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:20 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:20 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:20 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.86 | nll_loss 7.411 | ppl 170.22 | bleu 1.67 | wps 882.3 | wpb 563 | bsz 50 | num_updates 153 | best_bleu 1.67
2023-11-04 10:16:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 153 updates
2023-11-04 10:16:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 51 @ 153 updates, score 1.67) (writing took 1.6511857453733683 seconds)
2023-11-04 10:16:22 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-11-04 10:16:22 | INFO | train | epoch 051 | loss 7.96 | nll_loss 7.57 | ppl 190 | wps 2976 | ups 1.16 | wpb 2567.7 | bsz 266.7 | num_updates 153 | lr 1.9125e-05 | gnorm 1.769 | train_wall 0 | gb_free 45.8 | wall 122
2023-11-04 10:16:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:22 | INFO | fairseq.trainer | begin training epoch 52
2023-11-04 10:16:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:23 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:23 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:23 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:16:23 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:23 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 7.805 | nll_loss 7.355 | ppl 163.67 | bleu 1.88 | wps 808.9 | wpb 563 | bsz 50 | num_updates 156 | best_bleu 1.88
2023-11-04 10:16:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 156 updates
2023-11-04 10:16:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 52 @ 156 updates, score 1.88) (writing took 1.6805899646133184 seconds)
2023-11-04 10:16:25 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2023-11-04 10:16:25 | INFO | train | epoch 052 | loss 7.92 | nll_loss 7.525 | ppl 184.17 | wps 2820.6 | ups 1.1 | wpb 2567.7 | bsz 266.7 | num_updates 156 | lr 1.95e-05 | gnorm 1.523 | train_wall 0 | gb_free 45.8 | wall 124
2023-11-04 10:16:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:25 | INFO | fairseq.trainer | begin training epoch 53
2023-11-04 10:16:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:25 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:25 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:25 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:25 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:25 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 7.777 | nll_loss 7.321 | ppl 159.94 | bleu 2.16 | wps 985.6 | wpb 563 | bsz 50 | num_updates 159 | best_bleu 2.16
2023-11-04 10:16:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 159 updates
2023-11-04 10:16:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 53 @ 159 updates, score 2.16) (writing took 1.6787436697632074 seconds)
2023-11-04 10:16:27 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2023-11-04 10:16:27 | INFO | train | epoch 053 | loss 7.873 | nll_loss 7.474 | ppl 177.77 | wps 3203.2 | ups 1.25 | wpb 2567.7 | bsz 266.7 | num_updates 159 | lr 1.9875e-05 | gnorm 1.443 | train_wall 0 | gb_free 45.8 | wall 127
2023-11-04 10:16:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:27 | INFO | fairseq.trainer | begin training epoch 54
2023-11-04 10:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:28 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:28 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:28 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:28 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:28 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 7.753 | nll_loss 7.291 | ppl 156.59 | bleu 2.23 | wps 536.4 | wpb 563 | bsz 50 | num_updates 162 | best_bleu 2.23
2023-11-04 10:16:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 162 updates
2023-11-04 10:16:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 54 @ 162 updates, score 2.23) (writing took 1.6869487408548594 seconds)
2023-11-04 10:16:30 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2023-11-04 10:16:30 | INFO | train | epoch 054 | loss 7.86 | nll_loss 7.456 | ppl 175.58 | wps 2878.7 | ups 1.12 | wpb 2567.7 | bsz 266.7 | num_updates 162 | lr 2.025e-05 | gnorm 1.407 | train_wall 0 | gb_free 45.8 | wall 130
2023-11-04 10:16:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:30 | INFO | fairseq.trainer | begin training epoch 55
2023-11-04 10:16:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:31 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:31 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:31 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:16:31 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:31 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 7.73 | nll_loss 7.263 | ppl 153.58 | bleu 2.3 | wps 898.5 | wpb 563 | bsz 50 | num_updates 165 | best_bleu 2.3
2023-11-04 10:16:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 165 updates
2023-11-04 10:16:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 55 @ 165 updates, score 2.3) (writing took 1.6559687107801437 seconds)
2023-11-04 10:16:32 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2023-11-04 10:16:32 | INFO | train | epoch 055 | loss 7.821 | nll_loss 7.41 | ppl 170.11 | wps 3042.6 | ups 1.18 | wpb 2567.7 | bsz 266.7 | num_updates 165 | lr 2.0625e-05 | gnorm 1.289 | train_wall 0 | gb_free 45.8 | wall 132
2023-11-04 10:16:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:32 | INFO | fairseq.trainer | begin training epoch 56
2023-11-04 10:16:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:33 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:33 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:33 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:16:33 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:33 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 7.693 | nll_loss 7.223 | ppl 149.4 | bleu 2.79 | wps 876.4 | wpb 563 | bsz 50 | num_updates 168 | best_bleu 2.79
2023-11-04 10:16:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 168 updates
2023-11-04 10:16:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 56 @ 168 updates, score 2.79) (writing took 1.671586723998189 seconds)
2023-11-04 10:16:35 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2023-11-04 10:16:35 | INFO | train | epoch 056 | loss 7.802 | nll_loss 7.387 | ppl 167.38 | wps 3126.3 | ups 1.22 | wpb 2567.7 | bsz 266.7 | num_updates 168 | lr 2.1e-05 | gnorm 1.288 | train_wall 0 | gb_free 45.9 | wall 135
2023-11-04 10:16:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:35 | INFO | fairseq.trainer | begin training epoch 57
2023-11-04 10:16:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:36 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:16:36 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:36 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:16:36 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:36 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 7.655 | nll_loss 7.182 | ppl 145.23 | bleu 2.74 | wps 624.6 | wpb 563 | bsz 50 | num_updates 171 | best_bleu 2.79
2023-11-04 10:16:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 171 updates
2023-11-04 10:16:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 57 @ 171 updates, score 2.74) (writing took 1.1218397319316864 seconds)
2023-11-04 10:16:37 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2023-11-04 10:16:37 | INFO | train | epoch 057 | loss 7.753 | nll_loss 7.334 | ppl 161.35 | wps 3307.7 | ups 1.29 | wpb 2567.7 | bsz 266.7 | num_updates 171 | lr 2.1375e-05 | gnorm 1.24 | train_wall 0 | gb_free 45.8 | wall 137
2023-11-04 10:16:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:37 | INFO | fairseq.trainer | begin training epoch 58
2023-11-04 10:16:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:38 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:16:38 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:38 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:16:38 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:38 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 7.628 | nll_loss 7.147 | ppl 141.75 | bleu 3.3 | wps 786.4 | wpb 563 | bsz 50 | num_updates 174 | best_bleu 3.3
2023-11-04 10:16:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 174 updates
2023-11-04 10:16:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 58 @ 174 updates, score 3.3) (writing took 1.7939441855996847 seconds)
2023-11-04 10:16:40 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2023-11-04 10:16:40 | INFO | train | epoch 058 | loss 7.731 | nll_loss 7.306 | ppl 158.28 | wps 2798 | ups 1.09 | wpb 2567.7 | bsz 266.7 | num_updates 174 | lr 2.175e-05 | gnorm 1.243 | train_wall 0 | gb_free 45.8 | wall 140
2023-11-04 10:16:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:40 | INFO | fairseq.trainer | begin training epoch 59
2023-11-04 10:16:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:41 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:16:41 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:41 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:16:41 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:41 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 7.596 | nll_loss 7.111 | ppl 138.22 | bleu 3.63 | wps 698.5 | wpb 563 | bsz 50 | num_updates 177 | best_bleu 3.63
2023-11-04 10:16:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 177 updates
2023-11-04 10:16:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:16:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_best.pt (epoch 59 @ 177 updates, score 3.63) (writing took 1.866625215858221 seconds)
2023-11-04 10:16:43 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2023-11-04 10:16:43 | INFO | train | epoch 059 | loss 7.708 | nll_loss 7.277 | ppl 155.1 | wps 2732.1 | ups 1.06 | wpb 2567.7 | bsz 266.7 | num_updates 177 | lr 2.2125e-05 | gnorm 1.219 | train_wall 0 | gb_free 45.8 | wall 142
2023-11-04 10:16:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:43 | INFO | fairseq.trainer | begin training epoch 60
2023-11-04 10:16:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:44 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:16:44 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:44 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:16:44 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:44 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 7.554 | nll_loss 7.068 | ppl 134.21 | bleu 3.1 | wps 666 | wpb 563 | bsz 50 | num_updates 180 | best_bleu 3.63
2023-11-04 10:16:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 180 updates
2023-11-04 10:16:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 60 @ 180 updates, score 3.1) (writing took 1.1663305051624775 seconds)
2023-11-04 10:16:45 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2023-11-04 10:16:45 | INFO | train | epoch 060 | loss 7.676 | nll_loss 7.242 | ppl 151.43 | wps 3512.2 | ups 1.37 | wpb 2567.7 | bsz 266.7 | num_updates 180 | lr 2.25e-05 | gnorm 1.184 | train_wall 0 | gb_free 45.9 | wall 145
2023-11-04 10:16:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:45 | INFO | fairseq.trainer | begin training epoch 61
2023-11-04 10:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:46 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:16:46 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:46 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:16:46 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:46 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 7.532 | nll_loss 7.039 | ppl 131.55 | bleu 3.11 | wps 484.4 | wpb 563 | bsz 50 | num_updates 183 | best_bleu 3.63
2023-11-04 10:16:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 183 updates
2023-11-04 10:16:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 61 @ 183 updates, score 3.11) (writing took 1.10776393301785 seconds)
2023-11-04 10:16:47 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2023-11-04 10:16:47 | INFO | train | epoch 061 | loss 7.65 | nll_loss 7.214 | ppl 148.5 | wps 3629.1 | ups 1.41 | wpb 2567.7 | bsz 266.7 | num_updates 183 | lr 2.2875e-05 | gnorm 1.284 | train_wall 0 | gb_free 45.9 | wall 147
2023-11-04 10:16:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:47 | INFO | fairseq.trainer | begin training epoch 62
2023-11-04 10:16:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:48 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:16:48 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:48 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the
2023-11-04 10:16:48 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:48 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 7.513 | nll_loss 7.014 | ppl 129.28 | bleu 2.77 | wps 602.6 | wpb 563 | bsz 50 | num_updates 186 | best_bleu 3.63
2023-11-04 10:16:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 186 updates
2023-11-04 10:16:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 62 @ 186 updates, score 2.77) (writing took 1.1716441195458174 seconds)
2023-11-04 10:16:49 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2023-11-04 10:16:49 | INFO | train | epoch 062 | loss 7.625 | nll_loss 7.182 | ppl 145.19 | wps 3800.5 | ups 1.48 | wpb 2567.7 | bsz 266.7 | num_updates 186 | lr 2.325e-05 | gnorm 1.125 | train_wall 0 | gb_free 45.8 | wall 149
2023-11-04 10:16:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:49 | INFO | fairseq.trainer | begin training epoch 63
2023-11-04 10:16:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:50 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:16:50 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:50 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the
2023-11-04 10:16:50 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:50 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 7.486 | nll_loss 6.982 | ppl 126.39 | bleu 2.8 | wps 597 | wpb 563 | bsz 50 | num_updates 189 | best_bleu 3.63
2023-11-04 10:16:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 189 updates
2023-11-04 10:16:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 63 @ 189 updates, score 2.8) (writing took 1.11149463057518 seconds)
2023-11-04 10:16:51 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2023-11-04 10:16:51 | INFO | train | epoch 063 | loss 7.593 | nll_loss 7.142 | ppl 141.25 | wps 3944.5 | ups 1.54 | wpb 2567.7 | bsz 266.7 | num_updates 189 | lr 2.3625e-05 | gnorm 1.158 | train_wall 0 | gb_free 45.8 | wall 151
2023-11-04 10:16:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:51 | INFO | fairseq.trainer | begin training epoch 64
2023-11-04 10:16:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:52 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the
2023-11-04 10:16:52 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:52 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the
2023-11-04 10:16:52 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:52 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 7.462 | nll_loss 6.955 | ppl 124.08 | bleu 2.37 | wps 474 | wpb 563 | bsz 50 | num_updates 192 | best_bleu 3.63
2023-11-04 10:16:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 192 updates
2023-11-04 10:16:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 64 @ 192 updates, score 2.37) (writing took 1.1222121994942427 seconds)
2023-11-04 10:16:53 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2023-11-04 10:16:53 | INFO | train | epoch 064 | loss 7.569 | nll_loss 7.114 | ppl 138.55 | wps 3775.1 | ups 1.47 | wpb 2567.7 | bsz 266.7 | num_updates 192 | lr 2.4e-05 | gnorm 1.293 | train_wall 0 | gb_free 45.9 | wall 153
2023-11-04 10:16:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:53 | INFO | fairseq.trainer | begin training epoch 65
2023-11-04 10:16:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:54 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the
2023-11-04 10:16:54 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:54 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the
2023-11-04 10:16:54 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:54 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 7.435 | nll_loss 6.925 | ppl 121.5 | bleu 2.45 | wps 495.8 | wpb 563 | bsz 50 | num_updates 195 | best_bleu 3.63
2023-11-04 10:16:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 195 updates
2023-11-04 10:16:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 65 @ 195 updates, score 2.45) (writing took 1.1188240926712751 seconds)
2023-11-04 10:16:55 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2023-11-04 10:16:55 | INFO | train | epoch 065 | loss 7.55 | nll_loss 7.095 | ppl 136.67 | wps 3775.9 | ups 1.47 | wpb 2567.7 | bsz 266.7 | num_updates 195 | lr 2.4375e-05 | gnorm 1.566 | train_wall 0 | gb_free 45.8 | wall 155
2023-11-04 10:16:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:55 | INFO | fairseq.trainer | begin training epoch 66
2023-11-04 10:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:56 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the
2023-11-04 10:16:56 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:56 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the the the
2023-11-04 10:16:56 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:56 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 7.427 | nll_loss 6.911 | ppl 120.37 | bleu 2.12 | wps 434.5 | wpb 563 | bsz 50 | num_updates 198 | best_bleu 3.63
2023-11-04 10:16:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 198 updates
2023-11-04 10:16:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 66 @ 198 updates, score 2.12) (writing took 1.108493510633707 seconds)
2023-11-04 10:16:57 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2023-11-04 10:16:57 | INFO | train | epoch 066 | loss 7.515 | nll_loss 7.052 | ppl 132.69 | wps 3751.1 | ups 1.46 | wpb 2567.7 | bsz 266.7 | num_updates 198 | lr 2.475e-05 | gnorm 1.438 | train_wall 0 | gb_free 45.8 | wall 157
2023-11-04 10:16:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:16:57 | INFO | fairseq.trainer | begin training epoch 67
2023-11-04 10:16:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:16:57 | INFO | train_inner | epoch 067:      2 / 3 loss=8.024, nll_loss=7.643, ppl=199.91, wps=3394.6, ups=1.32, wpb=2568.1, bsz=266.6, num_updates=200, lr=2.5e-05, gnorm=1.527, train_wall=13, gb_free=45.8, wall=157
2023-11-04 10:16:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:16:58 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the the the the the the
2023-11-04 10:16:58 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:16:58 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the the the the the the the the
2023-11-04 10:16:58 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:16:58 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 7.414 | nll_loss 6.896 | ppl 119.1 | bleu 1.43 | wps 192.9 | wpb 563 | bsz 50 | num_updates 201 | best_bleu 3.63
2023-11-04 10:16:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 201 updates
2023-11-04 10:16:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:16:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 67 @ 201 updates, score 1.43) (writing took 1.1065836306661367 seconds)
2023-11-04 10:17:00 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2023-11-04 10:17:00 | INFO | train | epoch 067 | loss 7.488 | nll_loss 7.021 | ppl 129.84 | wps 3239.4 | ups 1.26 | wpb 2567.7 | bsz 266.7 | num_updates 201 | lr 2.5125e-05 | gnorm 1.2 | train_wall 0 | gb_free 45.9 | wall 159
2023-11-04 10:17:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:00 | INFO | fairseq.trainer | begin training epoch 68
2023-11-04 10:17:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:01 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the the the the the the the
2023-11-04 10:17:01 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:01 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the the the the the the the the the the
2023-11-04 10:17:01 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:01 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 7.391 | nll_loss 6.871 | ppl 117.02 | bleu 1.37 | wps 259.7 | wpb 563 | bsz 50 | num_updates 204 | best_bleu 3.63
2023-11-04 10:17:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 204 updates
2023-11-04 10:17:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 68 @ 204 updates, score 1.37) (writing took 1.2139374613761902 seconds)
2023-11-04 10:17:02 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2023-11-04 10:17:02 | INFO | train | epoch 068 | loss 7.467 | nll_loss 6.997 | ppl 127.72 | wps 2973.6 | ups 1.16 | wpb 2567.7 | bsz 266.7 | num_updates 204 | lr 2.55e-05 | gnorm 1.527 | train_wall 0 | gb_free 45.9 | wall 162
2023-11-04 10:17:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:02 | INFO | fairseq.trainer | begin training epoch 69
2023-11-04 10:17:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:03 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the the the the the the the the the the the the the
2023-11-04 10:17:03 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:03 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the the the the the the the the the the the the the the the the the the
2023-11-04 10:17:03 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:03 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 7.387 | nll_loss 6.861 | ppl 116.25 | bleu 1.05 | wps 238 | wpb 563 | bsz 50 | num_updates 207 | best_bleu 3.63
2023-11-04 10:17:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 207 updates
2023-11-04 10:17:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 69 @ 207 updates, score 1.05) (writing took 1.1193145923316479 seconds)
2023-11-04 10:17:05 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2023-11-04 10:17:05 | INFO | train | epoch 069 | loss 7.426 | nll_loss 6.951 | ppl 123.75 | wps 3076.4 | ups 1.2 | wpb 2567.7 | bsz 266.7 | num_updates 207 | lr 2.5875e-05 | gnorm 1.276 | train_wall 0 | gb_free 45.9 | wall 164
2023-11-04 10:17:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:05 | INFO | fairseq.trainer | begin training epoch 70
2023-11-04 10:17:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:06 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2023-11-04 10:17:06 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:06 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2023-11-04 10:17:06 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:06 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 7.379 | nll_loss 6.848 | ppl 115.22 | bleu 0.87 | wps 240 | wpb 563 | bsz 50 | num_updates 210 | best_bleu 3.63
2023-11-04 10:17:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 210 updates
2023-11-04 10:17:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 70 @ 210 updates, score 0.87) (writing took 1.1161407362669706 seconds)
2023-11-04 10:17:07 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2023-11-04 10:17:07 | INFO | train | epoch 070 | loss 7.412 | nll_loss 6.929 | ppl 121.84 | wps 3186.9 | ups 1.24 | wpb 2567.7 | bsz 266.7 | num_updates 210 | lr 2.625e-05 | gnorm 1.259 | train_wall 0 | gb_free 45.8 | wall 167
2023-11-04 10:17:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:07 | INFO | fairseq.trainer | begin training epoch 71
2023-11-04 10:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:08 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the the fofofofofofofofofofofofofofofofo
2023-11-04 10:17:08 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:08 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the the the the the babababababababababababababababababababa
2023-11-04 10:17:08 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:08 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 7.355 | nll_loss 6.824 | ppl 113.31 | bleu 1.12 | wps 237.9 | wpb 563 | bsz 50 | num_updates 213 | best_bleu 3.63
2023-11-04 10:17:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 213 updates
2023-11-04 10:17:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 71 @ 213 updates, score 1.12) (writing took 1.1128941848874092 seconds)
2023-11-04 10:17:09 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2023-11-04 10:17:09 | INFO | train | epoch 071 | loss 7.374 | nll_loss 6.889 | ppl 118.54 | wps 3232.3 | ups 1.26 | wpb 2567.7 | bsz 266.7 | num_updates 213 | lr 2.6625e-05 | gnorm 1.251 | train_wall 0 | gb_free 45.8 | wall 169
2023-11-04 10:17:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:09 | INFO | fairseq.trainer | begin training epoch 72
2023-11-04 10:17:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:10 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the the the the the the the the the the the the the the fofofofofofofofofofofofo
2023-11-04 10:17:10 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:11 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the bababababababababababababababababababa
2023-11-04 10:17:11 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:11 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 7.347 | nll_loss 6.805 | ppl 111.81 | bleu 0.92 | wps 196.1 | wpb 563 | bsz 50 | num_updates 216 | best_bleu 3.63
2023-11-04 10:17:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 216 updates
2023-11-04 10:17:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 72 @ 216 updates, score 0.92) (writing took 1.1680350787937641 seconds)
2023-11-04 10:17:12 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2023-11-04 10:17:12 | INFO | train | epoch 072 | loss 7.363 | nll_loss 6.875 | ppl 117.36 | wps 2899.5 | ups 1.13 | wpb 2567.7 | bsz 266.7 | num_updates 216 | lr 2.7e-05 | gnorm 1.3 | train_wall 0 | gb_free 45.9 | wall 172
2023-11-04 10:17:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:12 | INFO | fairseq.trainer | begin training epoch 73
2023-11-04 10:17:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:13 | INFO | fairseq.tasks.translation | example hypothesis: he the the the the the the the the fofofofofofofofofofofofofo
2023-11-04 10:17:13 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:14 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the babababababababababababababababababababababababababa
2023-11-04 10:17:14 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:14 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 7.322 | nll_loss 6.781 | ppl 110 | bleu 1.42 | wps 239.8 | wpb 563 | bsz 50 | num_updates 219 | best_bleu 3.63
2023-11-04 10:17:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 219 updates
2023-11-04 10:17:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 73 @ 219 updates, score 1.42) (writing took 1.1108594983816147 seconds)
2023-11-04 10:17:15 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2023-11-04 10:17:15 | INFO | train | epoch 073 | loss 7.342 | nll_loss 6.846 | ppl 115.04 | wps 2973.9 | ups 1.16 | wpb 2567.7 | bsz 266.7 | num_updates 219 | lr 2.7375e-05 | gnorm 1.509 | train_wall 0 | gb_free 45.9 | wall 174
2023-11-04 10:17:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:15 | INFO | fairseq.trainer | begin training epoch 74
2023-11-04 10:17:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:16 | INFO | fairseq.tasks.translation | example hypothesis: I the the the the the the fofofofofofofofofofofofofofofofo
2023-11-04 10:17:16 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:16 | INFO | fairseq.tasks.translation | example hypothesis: you the the the the the the chuchuchuchuchuchuchuchuchuchuchuchuthe the the p p p p p p p p p p p p
2023-11-04 10:17:16 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:16 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 7.304 | nll_loss 6.763 | ppl 108.64 | bleu 1.73 | wps 238.2 | wpb 563 | bsz 50 | num_updates 222 | best_bleu 3.63
2023-11-04 10:17:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 222 updates
2023-11-04 10:17:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 74 @ 222 updates, score 1.73) (writing took 1.0999032873660326 seconds)
2023-11-04 10:17:17 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2023-11-04 10:17:17 | INFO | train | epoch 074 | loss 7.33 | nll_loss 6.841 | ppl 114.61 | wps 3102.7 | ups 1.21 | wpb 2567.7 | bsz 266.7 | num_updates 222 | lr 2.775e-05 | gnorm 1.671 | train_wall 0 | gb_free 45.8 | wall 177
2023-11-04 10:17:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:17 | INFO | fairseq.trainer | begin training epoch 75
2023-11-04 10:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:18 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the fofofofofofofofofofofofofofofo
2023-11-04 10:17:18 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:18 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2023-11-04 10:17:18 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:18 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 7.329 | nll_loss 6.784 | ppl 110.21 | bleu 0.85 | wps 242.1 | wpb 563 | bsz 50 | num_updates 225 | best_bleu 3.63
2023-11-04 10:17:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 225 updates
2023-11-04 10:17:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 75 @ 225 updates, score 0.85) (writing took 1.1261897347867489 seconds)
2023-11-04 10:17:20 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2023-11-04 10:17:20 | INFO | train | epoch 075 | loss 7.295 | nll_loss 6.793 | ppl 110.88 | wps 3141.5 | ups 1.22 | wpb 2567.7 | bsz 266.7 | num_updates 225 | lr 2.8125e-05 | gnorm 1.687 | train_wall 0 | gb_free 45.8 | wall 179
2023-11-04 10:17:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:20 | INFO | fairseq.trainer | begin training epoch 76
2023-11-04 10:17:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:21 | INFO | fairseq.tasks.translation | example hypothesis: the fliflifliflifliflifliflifliflifli
2023-11-04 10:17:21 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:21 | INFO | fairseq.tasks.translation | example hypothesis: the gagagagagagagagagaga
2023-11-04 10:17:21 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:21 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 7.291 | nll_loss 6.741 | ppl 106.98 | bleu 2.52 | wps 316 | wpb 563 | bsz 50 | num_updates 228 | best_bleu 3.63
2023-11-04 10:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 228 updates
2023-11-04 10:17:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 76 @ 228 updates, score 2.52) (writing took 1.1047186702489853 seconds)
2023-11-04 10:17:22 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2023-11-04 10:17:22 | INFO | train | epoch 076 | loss 7.27 | nll_loss 6.767 | ppl 108.91 | wps 3354.7 | ups 1.31 | wpb 2567.7 | bsz 266.7 | num_updates 228 | lr 2.85e-05 | gnorm 1.893 | train_wall 0 | gb_free 45.8 | wall 182
2023-11-04 10:17:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:22 | INFO | fairseq.trainer | begin training epoch 77
2023-11-04 10:17:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:23 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the fofofofofofofofofofofofofofofofofothe the the the p p p p p
2023-11-04 10:17:23 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:23 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the babababababababababababababababababababababababababa
2023-11-04 10:17:23 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:23 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 7.29 | nll_loss 6.738 | ppl 106.75 | bleu 1.37 | wps 242.9 | wpb 563 | bsz 50 | num_updates 231 | best_bleu 3.63
2023-11-04 10:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 231 updates
2023-11-04 10:17:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 77 @ 231 updates, score 1.37) (writing took 1.1657069995999336 seconds)
2023-11-04 10:17:24 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2023-11-04 10:17:24 | INFO | train | epoch 077 | loss 7.261 | nll_loss 6.757 | ppl 108.14 | wps 3123.6 | ups 1.22 | wpb 2567.7 | bsz 266.7 | num_updates 231 | lr 2.8875e-05 | gnorm 2.168 | train_wall 0 | gb_free 45.8 | wall 184
2023-11-04 10:17:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:24 | INFO | fairseq.trainer | begin training epoch 78
2023-11-04 10:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:25 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofofofothe the p p p p p
2023-11-04 10:17:25 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:26 | INFO | fairseq.tasks.translation | example hypothesis: the gagagagagagagagathe the the bababababababa
2023-11-04 10:17:26 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:26 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 7.27 | nll_loss 6.706 | ppl 104.42 | bleu 2.44 | wps 248.5 | wpb 563 | bsz 50 | num_updates 234 | best_bleu 3.63
2023-11-04 10:17:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 234 updates
2023-11-04 10:17:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 78 @ 234 updates, score 2.44) (writing took 1.105603402480483 seconds)
2023-11-04 10:17:27 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2023-11-04 10:17:27 | INFO | train | epoch 078 | loss 7.234 | nll_loss 6.719 | ppl 105.37 | wps 3254.9 | ups 1.27 | wpb 2567.7 | bsz 266.7 | num_updates 234 | lr 2.925e-05 | gnorm 2.212 | train_wall 0 | gb_free 45.8 | wall 186
2023-11-04 10:17:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:27 | INFO | fairseq.trainer | begin training epoch 79
2023-11-04 10:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:28 | INFO | fairseq.tasks.translation | example hypothesis: the the the fofofofofofofofofofofothe the the the p p p p p p p p p p p p p
2023-11-04 10:17:28 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:28 | INFO | fairseq.tasks.translation | example hypothesis: the the the the gagagagagagagagagagagagagagagagagathe the the the the p p p p p p p p p
2023-11-04 10:17:28 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:28 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 7.262 | nll_loss 6.71 | ppl 104.71 | bleu 1.45 | wps 239.1 | wpb 563 | bsz 50 | num_updates 237 | best_bleu 3.63
2023-11-04 10:17:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 237 updates
2023-11-04 10:17:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 79 @ 237 updates, score 1.45) (writing took 1.1346723604947329 seconds)
2023-11-04 10:17:29 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2023-11-04 10:17:29 | INFO | train | epoch 079 | loss 7.227 | nll_loss 6.719 | ppl 105.36 | wps 3159 | ups 1.23 | wpb 2567.7 | bsz 266.7 | num_updates 237 | lr 2.9625e-05 | gnorm 2.77 | train_wall 0 | gb_free 45.8 | wall 189
2023-11-04 10:17:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:29 | INFO | fairseq.trainer | begin training epoch 80
2023-11-04 10:17:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:30 | INFO | fairseq.tasks.translation | example hypothesis: the the the fofofofofofofofothe the the the the the fafafafafafafafafafafa
2023-11-04 10:17:30 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:30 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the babababababababababababababababababababababababababa
2023-11-04 10:17:30 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:30 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 7.277 | nll_loss 6.706 | ppl 104.38 | bleu 1.46 | wps 240.1 | wpb 563 | bsz 50 | num_updates 240 | best_bleu 3.63
2023-11-04 10:17:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 240 updates
2023-11-04 10:17:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 80 @ 240 updates, score 1.46) (writing took 1.1155049912631512 seconds)
2023-11-04 10:17:32 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2023-11-04 10:17:32 | INFO | train | epoch 080 | loss 7.198 | nll_loss 6.677 | ppl 102.29 | wps 3211.7 | ups 1.25 | wpb 2567.7 | bsz 266.7 | num_updates 240 | lr 3e-05 | gnorm 1.961 | train_wall 0 | gb_free 45.8 | wall 191
2023-11-04 10:17:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:32 | INFO | fairseq.trainer | begin training epoch 81
2023-11-04 10:17:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:33 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofofofothe fafafafafa
2023-11-04 10:17:33 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:33 | INFO | fairseq.tasks.translation | example hypothesis: the gagagagagagagagagagagagaga
2023-11-04 10:17:33 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:33 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 7.228 | nll_loss 6.674 | ppl 102.09 | bleu 2.42 | wps 237.9 | wpb 563 | bsz 50 | num_updates 243 | best_bleu 3.63
2023-11-04 10:17:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 243 updates
2023-11-04 10:17:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 81 @ 243 updates, score 2.42) (writing took 1.1408805213868618 seconds)
2023-11-04 10:17:34 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2023-11-04 10:17:34 | INFO | train | epoch 081 | loss 7.167 | nll_loss 6.643 | ppl 99.94 | wps 3165 | ups 1.23 | wpb 2567.7 | bsz 266.7 | num_updates 243 | lr 3.0375e-05 | gnorm 2.299 | train_wall 0 | gb_free 45.9 | wall 194
2023-11-04 10:17:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:34 | INFO | fairseq.trainer | begin training epoch 82
2023-11-04 10:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:35 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofoflifliflifliflifliflifli
2023-11-04 10:17:35 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:35 | INFO | fairseq.tasks.translation | example hypothesis: the frufrufrufrufrufrufrufruthe the bababababababa
2023-11-04 10:17:35 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:35 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 7.221 | nll_loss 6.664 | ppl 101.37 | bleu 2.64 | wps 164.9 | wpb 563 | bsz 50 | num_updates 246 | best_bleu 3.63
2023-11-04 10:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 246 updates
2023-11-04 10:17:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 82 @ 246 updates, score 2.64) (writing took 1.163918124511838 seconds)
2023-11-04 10:17:37 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2023-11-04 10:17:37 | INFO | train | epoch 082 | loss 7.19 | nll_loss 6.679 | ppl 102.44 | wps 3001 | ups 1.17 | wpb 2567.7 | bsz 266.7 | num_updates 246 | lr 3.075e-05 | gnorm 3.241 | train_wall 0 | gb_free 45.9 | wall 196
2023-11-04 10:17:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:37 | INFO | fairseq.trainer | begin training epoch 83
2023-11-04 10:17:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:38 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the fofofofofofofofofofofofofofofofofofofothe the the the the p p
2023-11-04 10:17:38 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:38 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the bababababababababababababababababababababababababa
2023-11-04 10:17:38 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:38 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 7.247 | nll_loss 6.667 | ppl 101.6 | bleu 1.41 | wps 221.9 | wpb 563 | bsz 50 | num_updates 249 | best_bleu 3.63
2023-11-04 10:17:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 249 updates
2023-11-04 10:17:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 83 @ 249 updates, score 1.41) (writing took 1.1151350662112236 seconds)
2023-11-04 10:17:39 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2023-11-04 10:17:39 | INFO | train | epoch 083 | loss 7.133 | nll_loss 6.611 | ppl 97.76 | wps 2965.6 | ups 1.15 | wpb 2567.7 | bsz 266.7 | num_updates 249 | lr 3.1125e-05 | gnorm 1.817 | train_wall 0 | gb_free 45.9 | wall 199
2023-11-04 10:17:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:39 | INFO | fairseq.trainer | begin training epoch 84
2023-11-04 10:17:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:40 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofofofothe the fafafafafafafafafa
2023-11-04 10:17:40 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:41 | INFO | fairseq.tasks.translation | example hypothesis: the chuchuchuchuchuchuthe the the babababababababababababap p p p p p p p p p p p p
2023-11-04 10:17:41 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:41 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 7.25 | nll_loss 6.669 | ppl 101.77 | bleu 2.02 | wps 226.1 | wpb 563 | bsz 50 | num_updates 252 | best_bleu 3.63
2023-11-04 10:17:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 252 updates
2023-11-04 10:17:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 84 @ 252 updates, score 2.02) (writing took 1.2094216868281364 seconds)
2023-11-04 10:17:42 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2023-11-04 10:17:42 | INFO | train | epoch 084 | loss 7.107 | nll_loss 6.565 | ppl 94.68 | wps 2847.7 | ups 1.11 | wpb 2567.7 | bsz 266.7 | num_updates 252 | lr 3.15e-05 | gnorm 1.862 | train_wall 0 | gb_free 45.9 | wall 202
2023-11-04 10:17:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:42 | INFO | fairseq.trainer | begin training epoch 85
2023-11-04 10:17:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:43 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofofothe fafafafafafafafafafafa
2023-11-04 10:17:43 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:43 | INFO | fairseq.tasks.translation | example hypothesis: the chuchuchuchuchuchuchuthe the babababababababababababababababababababababa
2023-11-04 10:17:43 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:43 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 7.228 | nll_loss 6.658 | ppl 101.01 | bleu 2.39 | wps 233.8 | wpb 563 | bsz 50 | num_updates 255 | best_bleu 3.63
2023-11-04 10:17:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 255 updates
2023-11-04 10:17:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 85 @ 255 updates, score 2.39) (writing took 1.1202214863151312 seconds)
2023-11-04 10:17:45 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2023-11-04 10:17:45 | INFO | train | epoch 085 | loss 7.086 | nll_loss 6.553 | ppl 93.88 | wps 2945.2 | ups 1.15 | wpb 2567.7 | bsz 266.7 | num_updates 255 | lr 3.1875e-05 | gnorm 1.889 | train_wall 1 | gb_free 45.8 | wall 204
2023-11-04 10:17:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:45 | INFO | fairseq.trainer | begin training epoch 86
2023-11-04 10:17:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:46 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofofothe the fafafafafafafafa
2023-11-04 10:17:46 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:46 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the babababababababababababababababababababababababababababababa
2023-11-04 10:17:46 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:46 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 7.232 | nll_loss 6.643 | ppl 99.97 | bleu 2.14 | wps 245.7 | wpb 563 | bsz 50 | num_updates 258 | best_bleu 3.63
2023-11-04 10:17:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 258 updates
2023-11-04 10:17:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 86 @ 258 updates, score 2.14) (writing took 1.109436221420765 seconds)
2023-11-04 10:17:47 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2023-11-04 10:17:47 | INFO | train | epoch 086 | loss 7.037 | nll_loss 6.499 | ppl 90.42 | wps 3077.5 | ups 1.2 | wpb 2567.7 | bsz 266.7 | num_updates 258 | lr 3.225e-05 | gnorm 1.402 | train_wall 0 | gb_free 45.9 | wall 207
2023-11-04 10:17:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:47 | INFO | fairseq.trainer | begin training epoch 87
2023-11-04 10:17:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:48 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofofothe fafafafafafafa
2023-11-04 10:17:48 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:48 | INFO | fairseq.tasks.translation | example hypothesis: the chuchuchuchuchuthe babababababababababababababa
2023-11-04 10:17:48 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:48 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 7.173 | nll_loss 6.595 | ppl 96.7 | bleu 2.72 | wps 243 | wpb 563 | bsz 50 | num_updates 261 | best_bleu 3.63
2023-11-04 10:17:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 261 updates
2023-11-04 10:17:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 87 @ 261 updates, score 2.72) (writing took 1.100954331457615 seconds)
2023-11-04 10:17:49 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2023-11-04 10:17:50 | INFO | train | epoch 087 | loss 7.04 | nll_loss 6.498 | ppl 90.41 | wps 3099.4 | ups 1.21 | wpb 2567.7 | bsz 266.7 | num_updates 261 | lr 3.2625e-05 | gnorm 2.145 | train_wall 0 | gb_free 45.8 | wall 209
2023-11-04 10:17:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:50 | INFO | fairseq.trainer | begin training epoch 88
2023-11-04 10:17:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:51 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofofothe fafafafafafafa
2023-11-04 10:17:51 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:51 | INFO | fairseq.tasks.translation | example hypothesis: the chuchuchuchuchuthe the bababababababababababababababababababa
2023-11-04 10:17:51 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:51 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 7.203 | nll_loss 6.615 | ppl 98.05 | bleu 2.64 | wps 242.3 | wpb 563 | bsz 50 | num_updates 264 | best_bleu 3.63
2023-11-04 10:17:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 264 updates
2023-11-04 10:17:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 88 @ 264 updates, score 2.64) (writing took 1.1130882855504751 seconds)
2023-11-04 10:17:52 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2023-11-04 10:17:52 | INFO | train | epoch 088 | loss 7.019 | nll_loss 6.481 | ppl 89.3 | wps 3067.3 | ups 1.19 | wpb 2567.7 | bsz 266.7 | num_updates 264 | lr 3.3e-05 | gnorm 2.264 | train_wall 0 | gb_free 45.9 | wall 212
2023-11-04 10:17:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:52 | INFO | fairseq.trainer | begin training epoch 89
2023-11-04 10:17:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:53 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofothe the fofofofofofofofothe the fafafafafafafafafafafafafafa
2023-11-04 10:17:53 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:53 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the chuchuchuchuchubabababababababababababababababababababababababa
2023-11-04 10:17:53 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:53 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 7.25 | nll_loss 6.659 | ppl 101.06 | bleu 1.68 | wps 246.3 | wpb 563 | bsz 50 | num_updates 267 | best_bleu 3.63
2023-11-04 10:17:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 267 updates
2023-11-04 10:17:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 89 @ 267 updates, score 1.68) (writing took 1.11482834815979 seconds)
2023-11-04 10:17:54 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2023-11-04 10:17:54 | INFO | train | epoch 089 | loss 6.995 | nll_loss 6.452 | ppl 87.53 | wps 3152.6 | ups 1.23 | wpb 2567.7 | bsz 266.7 | num_updates 267 | lr 3.3375e-05 | gnorm 2.219 | train_wall 0 | gb_free 45.8 | wall 214
2023-11-04 10:17:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:55 | INFO | fairseq.trainer | begin training epoch 90
2023-11-04 10:17:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:56 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofofothe fafafafafafafafafa
2023-11-04 10:17:56 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:56 | INFO | fairseq.tasks.translation | example hypothesis: the chuchuchuchuchuchuthe the babababababababababababababababababababababababababa
2023-11-04 10:17:56 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:56 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 7.178 | nll_loss 6.588 | ppl 96.21 | bleu 2.53 | wps 238.7 | wpb 563 | bsz 50 | num_updates 270 | best_bleu 3.63
2023-11-04 10:17:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 270 updates
2023-11-04 10:17:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:17:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 90 @ 270 updates, score 2.53) (writing took 1.1148481778800488 seconds)
2023-11-04 10:17:57 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2023-11-04 10:17:57 | INFO | train | epoch 090 | loss 6.976 | nll_loss 6.421 | ppl 85.7 | wps 3006.3 | ups 1.17 | wpb 2567.7 | bsz 266.7 | num_updates 270 | lr 3.375e-05 | gnorm 2.074 | train_wall 0 | gb_free 45.9 | wall 217
2023-11-04 10:17:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:17:57 | INFO | fairseq.trainer | begin training epoch 91
2023-11-04 10:17:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:17:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:17:58 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofofothe fafafafafafafa
2023-11-04 10:17:58 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:17:59 | INFO | fairseq.tasks.translation | example hypothesis: the chuchuchuchuchuthe the bababababababababababababababababap p p p p p p p p p
2023-11-04 10:17:59 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:17:59 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 7.147 | nll_loss 6.548 | ppl 93.56 | bleu 2.51 | wps 224.9 | wpb 563 | bsz 50 | num_updates 273 | best_bleu 3.63
2023-11-04 10:17:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 273 updates
2023-11-04 10:17:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 91 @ 273 updates, score 2.51) (writing took 1.184563810005784 seconds)
2023-11-04 10:18:00 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2023-11-04 10:18:00 | INFO | train | epoch 091 | loss 6.934 | nll_loss 6.381 | ppl 83.32 | wps 2876.1 | ups 1.12 | wpb 2567.7 | bsz 266.7 | num_updates 273 | lr 3.4125e-05 | gnorm 1.396 | train_wall 0 | gb_free 45.9 | wall 219
2023-11-04 10:18:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:18:00 | INFO | fairseq.trainer | begin training epoch 92
2023-11-04 10:18:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:18:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:18:01 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofofothe fafafafafafafa
2023-11-04 10:18:01 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:18:01 | INFO | fairseq.tasks.translation | example hypothesis: the chuchuchuchuchuthe the bababababababababababababababababababababababababababa
2023-11-04 10:18:01 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:18:01 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 7.132 | nll_loss 6.53 | ppl 92.43 | bleu 2.63 | wps 221.5 | wpb 563 | bsz 50 | num_updates 276 | best_bleu 3.63
2023-11-04 10:18:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 276 updates
2023-11-04 10:18:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 92 @ 276 updates, score 2.63) (writing took 1.1218432821333408 seconds)
2023-11-04 10:18:02 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2023-11-04 10:18:02 | INFO | train | epoch 092 | loss 6.914 | nll_loss 6.354 | ppl 81.81 | wps 2928 | ups 1.14 | wpb 2567.7 | bsz 266.7 | num_updates 276 | lr 3.45e-05 | gnorm 1.886 | train_wall 0 | gb_free 45.8 | wall 222
2023-11-04 10:18:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:18:02 | INFO | fairseq.trainer | begin training epoch 93
2023-11-04 10:18:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:18:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:18:03 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofothe fafafafafafafafafa
2023-11-04 10:18:03 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:18:04 | INFO | fairseq.tasks.translation | example hypothesis: the chuchuchuchuchuthe babababababababababadidididididididididididididi
2023-11-04 10:18:04 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:18:04 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 7.165 | nll_loss 6.555 | ppl 94.02 | bleu 2.65 | wps 245.4 | wpb 563 | bsz 50 | num_updates 279 | best_bleu 3.63
2023-11-04 10:18:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 279 updates
2023-11-04 10:18:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 93 @ 279 updates, score 2.65) (writing took 1.2573105227202177 seconds)
2023-11-04 10:18:05 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2023-11-04 10:18:05 | INFO | train | epoch 093 | loss 6.878 | nll_loss 6.318 | ppl 79.78 | wps 2816.2 | ups 1.1 | wpb 2567.7 | bsz 266.7 | num_updates 279 | lr 3.4875e-05 | gnorm 1.54 | train_wall 0 | gb_free 45.9 | wall 225
2023-11-04 10:18:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:18:05 | INFO | fairseq.trainer | begin training epoch 94
2023-11-04 10:18:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:18:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:18:06 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofothe fafafafafameemeemeemeemeemeemeemeemee
2023-11-04 10:18:06 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:18:07 | INFO | fairseq.tasks.translation | example hypothesis: the chuchuchuchuchuthe bababababababababababaglogloglogloglogloglogloglogloglogloglogloglogloglo
2023-11-04 10:18:07 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:18:07 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 7.127 | nll_loss 6.526 | ppl 92.13 | bleu 2.25 | wps 234.9 | wpb 563 | bsz 50 | num_updates 282 | best_bleu 3.63
2023-11-04 10:18:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 282 updates
2023-11-04 10:18:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 94 @ 282 updates, score 2.25) (writing took 1.110864281654358 seconds)
2023-11-04 10:18:08 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2023-11-04 10:18:08 | INFO | train | epoch 094 | loss 6.851 | nll_loss 6.282 | ppl 77.84 | wps 2930.1 | ups 1.14 | wpb 2567.7 | bsz 266.7 | num_updates 282 | lr 3.525e-05 | gnorm 1.666 | train_wall 0 | gb_free 45.9 | wall 227
2023-11-04 10:18:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:18:08 | INFO | fairseq.trainer | begin training epoch 95
2023-11-04 10:18:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:18:09 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofofothe fafafameemeemee
2023-11-04 10:18:09 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:18:09 | INFO | fairseq.tasks.translation | example hypothesis: the chuchuchuchuchuchuthe babababababababababababababa
2023-11-04 10:18:09 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:18:09 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 7.164 | nll_loss 6.545 | ppl 93.39 | bleu 2.95 | wps 337.9 | wpb 563 | bsz 50 | num_updates 285 | best_bleu 3.63
2023-11-04 10:18:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 285 updates
2023-11-04 10:18:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 95 @ 285 updates, score 2.95) (writing took 1.1491975951939821 seconds)
2023-11-04 10:18:10 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2023-11-04 10:18:10 | INFO | train | epoch 095 | loss 6.833 | nll_loss 6.265 | ppl 76.9 | wps 3222.2 | ups 1.25 | wpb 2567.7 | bsz 266.7 | num_updates 285 | lr 3.5625e-05 | gnorm 2.044 | train_wall 0 | gb_free 45.8 | wall 230
2023-11-04 10:18:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:18:10 | INFO | fairseq.trainer | begin training epoch 96
2023-11-04 10:18:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:18:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:18:11 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofofothe fafafafafafafafafafa
2023-11-04 10:18:11 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:18:12 | INFO | fairseq.tasks.translation | example hypothesis: the chuchuchuchuchuchuthe bababababababababababababadidididididididididididididi
2023-11-04 10:18:12 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:18:12 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 7.099 | nll_loss 6.502 | ppl 90.66 | bleu 2.95 | wps 222.9 | wpb 563 | bsz 50 | num_updates 288 | best_bleu 3.63
2023-11-04 10:18:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 288 updates
2023-11-04 10:18:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 96 @ 288 updates, score 2.95) (writing took 1.1591837648302317 seconds)
2023-11-04 10:18:13 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2023-11-04 10:18:13 | INFO | train | epoch 096 | loss 6.825 | nll_loss 6.248 | ppl 75.99 | wps 2847 | ups 1.11 | wpb 2567.7 | bsz 266.7 | num_updates 288 | lr 3.6e-05 | gnorm 3.023 | train_wall 0 | gb_free 45.9 | wall 233
2023-11-04 10:18:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:18:13 | INFO | fairseq.trainer | begin training epoch 97
2023-11-04 10:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:18:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:18:14 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofofothe fafafameemeemeemeemee
2023-11-04 10:18:14 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:18:14 | INFO | fairseq.tasks.translation | example hypothesis: the chichichichichithe babababababap p p p p p p p
2023-11-04 10:18:14 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:18:14 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 7.166 | nll_loss 6.539 | ppl 93 | bleu 2.77 | wps 336.1 | wpb 563 | bsz 50 | num_updates 291 | best_bleu 3.63
2023-11-04 10:18:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 291 updates
2023-11-04 10:18:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 97 @ 291 updates, score 2.77) (writing took 1.153488090261817 seconds)
2023-11-04 10:18:15 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2023-11-04 10:18:15 | INFO | train | epoch 097 | loss 6.841 | nll_loss 6.271 | ppl 77.21 | wps 3183.3 | ups 1.24 | wpb 2567.7 | bsz 266.7 | num_updates 291 | lr 3.6375e-05 | gnorm 4.76 | train_wall 0 | gb_free 45.9 | wall 235
2023-11-04 10:18:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:18:15 | INFO | fairseq.trainer | begin training epoch 98
2023-11-04 10:18:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:18:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:18:16 | INFO | fairseq.tasks.translation | example hypothesis: the fafafafafafafafafameemeemeemeemeemeemeemee
2023-11-04 10:18:16 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:18:17 | INFO | fairseq.tasks.translation | example hypothesis: the chuchuchuchuchufliflifliflifliflifliflididididididip p p p p p p
2023-11-04 10:18:17 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:18:17 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 7.14 | nll_loss 6.555 | ppl 93.99 | bleu 2.42 | wps 215.4 | wpb 563 | bsz 50 | num_updates 294 | best_bleu 3.63
2023-11-04 10:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 294 updates
2023-11-04 10:18:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 98 @ 294 updates, score 2.42) (writing took 1.1202180683612823 seconds)
2023-11-04 10:18:18 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2023-11-04 10:18:18 | INFO | train | epoch 098 | loss 6.803 | nll_loss 6.224 | ppl 74.77 | wps 2919.5 | ups 1.14 | wpb 2567.7 | bsz 266.7 | num_updates 294 | lr 3.675e-05 | gnorm 3.391 | train_wall 0 | gb_free 45.8 | wall 238
2023-11-04 10:18:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:18:18 | INFO | fairseq.trainer | begin training epoch 99
2023-11-04 10:18:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:18:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:18:19 | INFO | fairseq.tasks.translation | example hypothesis: the fofofofothe fofothe fafafafafafafafafafafafafa
2023-11-04 10:18:19 | INFO | fairseq.tasks.translation | example reference: the jocholofibechud the flachochicobomax lochujichakeebirates
2023-11-04 10:18:19 | INFO | fairseq.tasks.translation | example hypothesis: the the the the bababababababababababababababababababababababababababababababa
2023-11-04 10:18:19 | INFO | fairseq.tasks.translation | example reference: the bulujikikaglup the mojaflumeefrojom mifloflokumafifizes
2023-11-04 10:18:19 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 7.256 | nll_loss 6.622 | ppl 98.5 | bleu 1.91 | wps 229.9 | wpb 563 | bsz 50 | num_updates 297 | best_bleu 3.63
2023-11-04 10:18:19 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 40 runs
2023-11-04 10:18:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 297 updates
2023-11-04 10:18:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_SOV_1.0k/checkpoints/checkpoint_last.pt (epoch 99 @ 297 updates, score 1.91) (writing took 1.117274347692728 seconds)
2023-11-04 10:18:20 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2023-11-04 10:18:20 | INFO | train | epoch 099 | loss 6.781 | nll_loss 6.21 | ppl 74.01 | wps 2950.1 | ups 1.15 | wpb 2567.7 | bsz 266.7 | num_updates 297 | lr 3.7125e-05 | gnorm 3.232 | train_wall 0 | gb_free 45.8 | wall 240
2023-11-04 10:18:20 | INFO | fairseq_cli.train | done training in 240.2 seconds
learn_bpe.py on /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/data/train.en-es...
apply_bpe.py to train.en...
apply_bpe.py to dev.en...
apply_bpe.py to test.en...
apply_bpe.py to train.es...
apply_bpe.py to dev.es...
apply_bpe.py to test.es...
2023-11-04 10:18:54 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/tensorboard_logs/', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1000, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 40, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir='/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/tensorboard_logs/', wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='chrf', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_iwslt_de_en', max_epoch=1000, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=40, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/data-bin', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_attention_heads=4, encoder_layers=6, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_iwslt_de_en'), 'task': {'_name': 'translation', 'data': '/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'chrf'}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-11-04 10:18:54 | INFO | fairseq.tasks.translation | [en] dictionary: 1232 types
2023-11-04 10:18:54 | INFO | fairseq.tasks.translation | [es] dictionary: 1232 types
2023-11-04 10:18:55 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(1232, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(1232, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=1232, bias=False)
  )
)
2023-11-04 10:18:55 | INFO | fairseq_cli.train | task: TranslationTask
2023-11-04 10:18:55 | INFO | fairseq_cli.train | model: TransformerModel
2023-11-04 10:18:55 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2023-11-04 10:18:55 | INFO | fairseq_cli.train | num. shared model params: 45,409,280 (num. trained: 45,409,280)
2023-11-04 10:18:55 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-11-04 10:18:55 | INFO | fairseq.data.data_utils | loaded 100 examples from: /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/data-bin/valid.en-es.en
2023-11-04 10:18:55 | INFO | fairseq.data.data_utils | loaded 100 examples from: /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/data-bin/valid.en-es.es
2023-11-04 10:18:55 | INFO | fairseq.tasks.translation | /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/data-bin valid en-es 100 examples
2023-11-04 10:18:57 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2023-11-04 10:18:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-11-04 10:18:57 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 47.544 GB ; name = NVIDIA RTX A6000                        
2023-11-04 10:18:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-11-04 10:18:57 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2023-11-04 10:18:57 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None
2023-11-04 10:18:57 | INFO | fairseq.trainer | Preparing to load checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:57 | INFO | fairseq.trainer | No existing checkpoint found /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:18:57 | INFO | fairseq.trainer | loading train data for epoch 1
2023-11-04 10:18:57 | INFO | fairseq.data.data_utils | loaded 800 examples from: /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/data-bin/train.en-es.en
2023-11-04 10:18:57 | INFO | fairseq.data.data_utils | loaded 800 examples from: /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/data-bin/train.en-es.es
2023-11-04 10:18:57 | INFO | fairseq.tasks.translation | /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/data-bin train en-es 800 examples
2023-11-04 10:18:57 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2023-11-04 10:18:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:18:57 | INFO | fairseq.trainer | begin training epoch 1
2023-11-04 10:18:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:18:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:18:59 | INFO | fairseq.tasks.translation | example hypothesis: glubichamolihaglubichamolihaglubichamolihafihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:18:59 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:18:59 | INFO | fairseq.tasks.translation | example hypothesis: fihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:18:59 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:18:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.203 | nll_loss 11.221 | ppl 2387.57 | bleu 0 | wps 222.1 | wpb 566.5 | bsz 50 | num_updates 3
2023-11-04 10:18:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 3 updates
2023-11-04 10:18:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt (epoch 1 @ 3 updates, score 0.0) (writing took 1.2703172359615564 seconds)
2023-11-04 10:19:01 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-11-04 10:19:01 | INFO | train | epoch 001 | loss 11.152 | nll_loss 11.169 | ppl 2301.87 | wps 2024.8 | ups 0.76 | wpb 2565.7 | bsz 266.7 | num_updates 3 | lr 3.75e-07 | gnorm 7.941 | train_wall 1 | gb_free 45.8 | wall 4
2023-11-04 10:19:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:01 | INFO | fairseq.trainer | begin training epoch 2
2023-11-04 10:19:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:02 | INFO | fairseq.tasks.translation | example hypothesis: glubichamolihaglubichamolihaglubichamolihafihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:19:02 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:02 | INFO | fairseq.tasks.translation | example hypothesis: fufafihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:19:02 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:02 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.155 | nll_loss 11.169 | ppl 2302.07 | bleu 0 | wps 210 | wpb 566.5 | bsz 50 | num_updates 6 | best_bleu 0
2023-11-04 10:19:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 6 updates
2023-11-04 10:19:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt (epoch 2 @ 6 updates, score 0.0) (writing took 1.5860810223966837 seconds)
2023-11-04 10:19:04 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-11-04 10:19:04 | INFO | train | epoch 002 | loss 11.118 | nll_loss 11.131 | ppl 2242.7 | wps 2479.3 | ups 0.97 | wpb 2565.7 | bsz 266.7 | num_updates 6 | lr 7.5e-07 | gnorm 7.936 | train_wall 0 | gb_free 46 | wall 7
2023-11-04 10:19:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:04 | INFO | fairseq.trainer | begin training epoch 3
2023-11-04 10:19:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:05 | INFO | fairseq.tasks.translation | example hypothesis: glubichamolihaglubichamolihaglubichamolihaglubichamolihafihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:19:05 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:05 | INFO | fairseq.tasks.translation | example hypothesis: fufafihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:19:05 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:05 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.072 | nll_loss 11.077 | ppl 2159.7 | bleu 0 | wps 221.8 | wpb 566.5 | bsz 50 | num_updates 9 | best_bleu 0
2023-11-04 10:19:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 9 updates
2023-11-04 10:19:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt (epoch 3 @ 9 updates, score 0.0) (writing took 1.7389681451022625 seconds)
2023-11-04 10:19:07 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-11-04 10:19:07 | INFO | train | epoch 003 | loss 11.096 | nll_loss 11.107 | ppl 2205.12 | wps 2345.5 | ups 0.91 | wpb 2565.7 | bsz 266.7 | num_updates 9 | lr 1.125e-06 | gnorm 7.966 | train_wall 1 | gb_free 46 | wall 10
2023-11-04 10:19:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:07 | INFO | fairseq.trainer | begin training epoch 4
2023-11-04 10:19:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:08 | INFO | fairseq.tasks.translation | example hypothesis: glubichamolihaglubichamolihaglubichamolihaglubichamolihaglubichamolihaglubichamolihaglubichamolihaglubichamolihafihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:19:08 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:08 | INFO | fairseq.tasks.translation | example hypothesis: fufafihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:19:08 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:08 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.954 | nll_loss 10.946 | ppl 1972.82 | bleu 0 | wps 221.4 | wpb 566.5 | bsz 50 | num_updates 12 | best_bleu 0
2023-11-04 10:19:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 12 updates
2023-11-04 10:19:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt (epoch 4 @ 12 updates, score 0.0) (writing took 1.4795424416661263 seconds)
2023-11-04 10:19:10 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-11-04 10:19:10 | INFO | train | epoch 004 | loss 11.004 | nll_loss 11.005 | ppl 2054.73 | wps 2583.3 | ups 1.01 | wpb 2565.7 | bsz 266.7 | num_updates 12 | lr 1.5e-06 | gnorm 7.925 | train_wall 0 | gb_free 46 | wall 13
2023-11-04 10:19:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:10 | INFO | fairseq.trainer | begin training epoch 5
2023-11-04 10:19:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:11 | INFO | fairseq.tasks.translation | example hypothesis: fihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:19:11 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:11 | INFO | fairseq.tasks.translation | example hypothesis: fihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:19:11 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:11 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.803 | nll_loss 10.778 | ppl 1756.45 | bleu 0 | wps 222.2 | wpb 566.5 | bsz 50 | num_updates 15 | best_bleu 0
2023-11-04 10:19:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 15 updates
2023-11-04 10:19:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt (epoch 5 @ 15 updates, score 0.0) (writing took 1.5812260918319225 seconds)
2023-11-04 10:19:13 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-11-04 10:19:13 | INFO | train | epoch 005 | loss 10.902 | nll_loss 10.891 | ppl 1898.91 | wps 2539.4 | ups 0.99 | wpb 2565.7 | bsz 266.7 | num_updates 15 | lr 1.875e-06 | gnorm 7.822 | train_wall 0 | gb_free 46 | wall 16
2023-11-04 10:19:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:13 | INFO | fairseq.trainer | begin training epoch 6
2023-11-04 10:19:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:14 | INFO | fairseq.tasks.translation | example hypothesis: fihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:19:14 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:14 | INFO | fairseq.tasks.translation | example hypothesis: fihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:19:14 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:14 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.621 | nll_loss 10.576 | ppl 1527.02 | bleu 0 | wps 233.9 | wpb 566.5 | bsz 50 | num_updates 18 | best_bleu 0
2023-11-04 10:19:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 18 updates
2023-11-04 10:19:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt (epoch 6 @ 18 updates, score 0.0) (writing took 1.4828860592097044 seconds)
2023-11-04 10:19:16 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-11-04 10:19:16 | INFO | train | epoch 006 | loss 10.779 | nll_loss 10.755 | ppl 1728.15 | wps 2692.4 | ups 1.05 | wpb 2565.7 | bsz 266.7 | num_updates 18 | lr 2.25e-06 | gnorm 7.725 | train_wall 0 | gb_free 45.8 | wall 19
2023-11-04 10:19:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:16 | INFO | fairseq.trainer | begin training epoch 7
2023-11-04 10:19:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:17 | INFO | fairseq.tasks.translation | example hypothesis: fihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:19:17 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:17 | INFO | fairseq.tasks.translation | example hypothesis: fihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihifihi
2023-11-04 10:19:17 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:17 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.415 | nll_loss 10.348 | ppl 1303.46 | bleu 0 | wps 237.2 | wpb 566.5 | bsz 50 | num_updates 21 | best_bleu 0
2023-11-04 10:19:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 21 updates
2023-11-04 10:19:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt (epoch 7 @ 21 updates, score 0.0) (writing took 1.4925122633576393 seconds)
2023-11-04 10:19:19 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-11-04 10:19:19 | INFO | train | epoch 007 | loss 10.599 | nll_loss 10.555 | ppl 1504.29 | wps 2719.6 | ups 1.06 | wpb 2565.7 | bsz 266.7 | num_updates 21 | lr 2.625e-06 | gnorm 7.584 | train_wall 0 | gb_free 45.8 | wall 22
2023-11-04 10:19:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:19 | INFO | fairseq.trainer | begin training epoch 8
2023-11-04 10:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:20 | INFO | fairseq.tasks.translation | example hypothesis: kufikufikufikufikufikufikufi
2023-11-04 10:19:20 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:20 | INFO | fairseq.tasks.translation | example hypothesis: fihifihifihifihifihifihifihi
2023-11-04 10:19:20 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:20 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.199 | nll_loss 10.108 | ppl 1103.26 | bleu 0 | wps 606 | wpb 566.5 | bsz 50 | num_updates 24 | best_bleu 0
2023-11-04 10:19:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 24 updates
2023-11-04 10:19:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt (epoch 8 @ 24 updates, score 0.0) (writing took 1.5451785549521446 seconds)
2023-11-04 10:19:21 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-11-04 10:19:21 | INFO | train | epoch 008 | loss 10.445 | nll_loss 10.383 | ppl 1335.3 | wps 2799.2 | ups 1.09 | wpb 2565.7 | bsz 266.7 | num_updates 24 | lr 3e-06 | gnorm 7.338 | train_wall 0 | gb_free 46 | wall 25
2023-11-04 10:19:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:21 | INFO | fairseq.trainer | begin training epoch 9
2023-11-04 10:19:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:22 | INFO | fairseq.tasks.translation | example hypothesis: kufikufikufi
2023-11-04 10:19:22 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:23 | INFO | fairseq.tasks.translation | example hypothesis: fihifihifihifihifihifihi
2023-11-04 10:19:23 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:23 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.989 | nll_loss 9.871 | ppl 936.42 | bleu 0.14 | wps 785 | wpb 566.5 | bsz 50 | num_updates 27 | best_bleu 0.14
2023-11-04 10:19:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 27 updates
2023-11-04 10:19:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt (epoch 9 @ 27 updates, score 0.14) (writing took 1.5075772274285555 seconds)
2023-11-04 10:19:24 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-11-04 10:19:24 | INFO | train | epoch 009 | loss 10.259 | nll_loss 10.176 | ppl 1157.26 | wps 2922.6 | ups 1.14 | wpb 2565.7 | bsz 266.7 | num_updates 27 | lr 3.375e-06 | gnorm 6.903 | train_wall 0 | gb_free 45.8 | wall 27
2023-11-04 10:19:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:24 | INFO | fairseq.trainer | begin training epoch 10
2023-11-04 10:19:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:25 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:19:25 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:25 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:25 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:25 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.81 | nll_loss 9.665 | ppl 811.92 | bleu 0.53 | wps 839.7 | wpb 566.5 | bsz 50 | num_updates 30 | best_bleu 0.53
2023-11-04 10:19:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 30 updates
2023-11-04 10:19:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt (epoch 10 @ 30 updates, score 0.53) (writing took 1.6072720792144537 seconds)
2023-11-04 10:19:27 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-11-04 10:19:27 | INFO | train | epoch 010 | loss 10.072 | nll_loss 9.967 | ppl 1000.91 | wps 3026.8 | ups 1.18 | wpb 2565.7 | bsz 266.7 | num_updates 30 | lr 3.75e-06 | gnorm 6.429 | train_wall 0 | gb_free 45.8 | wall 30
2023-11-04 10:19:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:27 | INFO | fairseq.trainer | begin training epoch 11
2023-11-04 10:19:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:27 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:19:27 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:28 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:19:28 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:28 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.691 | nll_loss 9.521 | ppl 734.69 | bleu 0.69 | wps 629 | wpb 566.5 | bsz 50 | num_updates 33 | best_bleu 0.69
2023-11-04 10:19:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 33 updates
2023-11-04 10:19:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:19:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_best.pt (epoch 11 @ 33 updates, score 0.69) (writing took 1.465083722025156 seconds)
2023-11-04 10:19:29 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-11-04 10:19:29 | INFO | train | epoch 011 | loss 9.904 | nll_loss 9.779 | ppl 878.33 | wps 3283.8 | ups 1.28 | wpb 2565.7 | bsz 266.7 | num_updates 33 | lr 4.125e-06 | gnorm 5.743 | train_wall 0 | gb_free 46 | wall 32
2023-11-04 10:19:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:29 | INFO | fairseq.trainer | begin training epoch 12
2023-11-04 10:19:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:30 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:19:30 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:30 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:30 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:30 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.654 | nll_loss 9.46 | ppl 704.42 | bleu 0.57 | wps 984.8 | wpb 566.5 | bsz 50 | num_updates 36 | best_bleu 0.69
2023-11-04 10:19:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 36 updates
2023-11-04 10:19:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 12 @ 36 updates, score 0.57) (writing took 1.084465542808175 seconds)
2023-11-04 10:19:31 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-11-04 10:19:31 | INFO | train | epoch 012 | loss 9.72 | nll_loss 9.57 | ppl 760.03 | wps 4180.5 | ups 1.63 | wpb 2565.7 | bsz 266.7 | num_updates 36 | lr 4.5e-06 | gnorm 4.917 | train_wall 0 | gb_free 46 | wall 34
2023-11-04 10:19:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:31 | INFO | fairseq.trainer | begin training epoch 13
2023-11-04 10:19:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:32 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:19:32 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:32 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:32 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:32 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.701 | nll_loss 9.486 | ppl 716.84 | bleu 0.46 | wps 864 | wpb 566.5 | bsz 50 | num_updates 39 | best_bleu 0.69
2023-11-04 10:19:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 39 updates
2023-11-04 10:19:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 13 @ 39 updates, score 0.46) (writing took 0.9383351821452379 seconds)
2023-11-04 10:19:33 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-11-04 10:19:33 | INFO | train | epoch 013 | loss 9.589 | nll_loss 9.419 | ppl 684.48 | wps 4386.3 | ups 1.71 | wpb 2565.7 | bsz 266.7 | num_updates 39 | lr 4.875e-06 | gnorm 4.148 | train_wall 0 | gb_free 45.8 | wall 36
2023-11-04 10:19:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:33 | INFO | fairseq.trainer | begin training epoch 14
2023-11-04 10:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:33 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:19:33 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:33 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:33 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:33 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.784 | nll_loss 9.552 | ppl 750.53 | bleu 0.41 | wps 995 | wpb 566.5 | bsz 50 | num_updates 42 | best_bleu 0.69
2023-11-04 10:19:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 42 updates
2023-11-04 10:19:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 14 @ 42 updates, score 0.41) (writing took 0.9040038846433163 seconds)
2023-11-04 10:19:34 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-11-04 10:19:34 | INFO | train | epoch 014 | loss 9.487 | nll_loss 9.298 | ppl 629.44 | wps 4641.1 | ups 1.81 | wpb 2565.7 | bsz 266.7 | num_updates 42 | lr 5.25e-06 | gnorm 3.441 | train_wall 0 | gb_free 45.8 | wall 38
2023-11-04 10:19:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:34 | INFO | fairseq.trainer | begin training epoch 15
2023-11-04 10:19:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:35 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:19:35 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:35 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:35 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:35 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.797 | nll_loss 9.55 | ppl 749.84 | bleu 0.4 | wps 997.5 | wpb 566.5 | bsz 50 | num_updates 45 | best_bleu 0.69
2023-11-04 10:19:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 45 updates
2023-11-04 10:19:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 15 @ 45 updates, score 0.4) (writing took 0.9981555640697479 seconds)
2023-11-04 10:19:36 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-11-04 10:19:36 | INFO | train | epoch 015 | loss 9.417 | nll_loss 9.212 | ppl 592.89 | wps 4331.3 | ups 1.69 | wpb 2565.7 | bsz 266.7 | num_updates 45 | lr 5.625e-06 | gnorm 3.522 | train_wall 0 | gb_free 45.8 | wall 39
2023-11-04 10:19:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:36 | INFO | fairseq.trainer | begin training epoch 16
2023-11-04 10:19:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:37 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:19:37 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:37 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:37 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:37 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.69 | nll_loss 9.435 | ppl 692.13 | bleu 0.44 | wps 864.7 | wpb 566.5 | bsz 50 | num_updates 48 | best_bleu 0.69
2023-11-04 10:19:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 48 updates
2023-11-04 10:19:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 16 @ 48 updates, score 0.44) (writing took 0.9262696858495474 seconds)
2023-11-04 10:19:38 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-11-04 10:19:38 | INFO | train | epoch 016 | loss 9.372 | nll_loss 9.158 | ppl 571.26 | wps 4178.9 | ups 1.63 | wpb 2565.7 | bsz 266.7 | num_updates 48 | lr 6e-06 | gnorm 3.556 | train_wall 0 | gb_free 45.8 | wall 41
2023-11-04 10:19:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:38 | INFO | fairseq.trainer | begin training epoch 17
2023-11-04 10:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:39 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:19:39 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:39 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:39 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:39 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.518 | nll_loss 9.257 | ppl 611.65 | bleu 0.47 | wps 596.5 | wpb 566.5 | bsz 50 | num_updates 51 | best_bleu 0.69
2023-11-04 10:19:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 51 updates
2023-11-04 10:19:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 17 @ 51 updates, score 0.47) (writing took 0.9254001397639513 seconds)
2023-11-04 10:19:40 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-11-04 10:19:40 | INFO | train | epoch 017 | loss 9.293 | nll_loss 9.07 | ppl 537.52 | wps 4423.5 | ups 1.72 | wpb 2565.7 | bsz 266.7 | num_updates 51 | lr 6.375e-06 | gnorm 3.323 | train_wall 0 | gb_free 46 | wall 43
2023-11-04 10:19:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:40 | INFO | fairseq.trainer | begin training epoch 18
2023-11-04 10:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:40 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:19:40 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:40 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:40 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:40 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.328 | nll_loss 9.064 | ppl 535.29 | bleu 0.47 | wps 975.2 | wpb 566.5 | bsz 50 | num_updates 54 | best_bleu 0.69
2023-11-04 10:19:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 54 updates
2023-11-04 10:19:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 18 @ 54 updates, score 0.47) (writing took 0.9306769073009491 seconds)
2023-11-04 10:19:41 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-11-04 10:19:41 | INFO | train | epoch 018 | loss 9.21 | nll_loss 8.981 | ppl 505.25 | wps 4552 | ups 1.77 | wpb 2565.7 | bsz 266.7 | num_updates 54 | lr 6.75e-06 | gnorm 2.902 | train_wall 0 | gb_free 45.8 | wall 45
2023-11-04 10:19:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:41 | INFO | fairseq.trainer | begin training epoch 19
2023-11-04 10:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:42 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:19:42 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:42 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:42 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:42 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.195 | nll_loss 8.928 | ppl 487.19 | bleu 0.46 | wps 761.7 | wpb 566.5 | bsz 50 | num_updates 57 | best_bleu 0.69
2023-11-04 10:19:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 57 updates
2023-11-04 10:19:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 19 @ 57 updates, score 0.46) (writing took 0.9159000292420387 seconds)
2023-11-04 10:19:43 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-11-04 10:19:43 | INFO | train | epoch 019 | loss 9.159 | nll_loss 8.929 | ppl 487.34 | wps 4135.4 | ups 1.61 | wpb 2565.7 | bsz 266.7 | num_updates 57 | lr 7.125e-06 | gnorm 2.682 | train_wall 0 | gb_free 46 | wall 46
2023-11-04 10:19:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:43 | INFO | fairseq.trainer | begin training epoch 20
2023-11-04 10:19:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:44 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:19:44 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:44 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:44 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:44 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.107 | nll_loss 8.836 | ppl 457.06 | bleu 0.44 | wps 976 | wpb 566.5 | bsz 50 | num_updates 60 | best_bleu 0.69
2023-11-04 10:19:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 60 updates
2023-11-04 10:19:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 20 @ 60 updates, score 0.44) (writing took 0.9777921792119741 seconds)
2023-11-04 10:19:45 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-11-04 10:19:45 | INFO | train | epoch 020 | loss 9.093 | nll_loss 8.857 | ppl 463.59 | wps 4422 | ups 1.72 | wpb 2565.7 | bsz 266.7 | num_updates 60 | lr 7.5e-06 | gnorm 2.656 | train_wall 0 | gb_free 45.8 | wall 48
2023-11-04 10:19:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:45 | INFO | fairseq.trainer | begin training epoch 21
2023-11-04 10:19:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:46 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:46 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:46 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:46 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:46 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.045 | nll_loss 8.769 | ppl 436.1 | bleu 0.42 | wps 973.7 | wpb 566.5 | bsz 50 | num_updates 63 | best_bleu 0.69
2023-11-04 10:19:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 63 updates
2023-11-04 10:19:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 21 @ 63 updates, score 0.42) (writing took 1.094479376450181 seconds)
2023-11-04 10:19:47 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-11-04 10:19:47 | INFO | train | epoch 021 | loss 9.06 | nll_loss 8.821 | ppl 452.2 | wps 4074.7 | ups 1.59 | wpb 2565.7 | bsz 266.7 | num_updates 63 | lr 7.875e-06 | gnorm 2.667 | train_wall 0 | gb_free 45.8 | wall 50
2023-11-04 10:19:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:47 | INFO | fairseq.trainer | begin training epoch 22
2023-11-04 10:19:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:48 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:19:48 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:48 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:48 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:48 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.009 | nll_loss 8.726 | ppl 423.32 | bleu 0.42 | wps 873.2 | wpb 566.5 | bsz 50 | num_updates 66 | best_bleu 0.69
2023-11-04 10:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 66 updates
2023-11-04 10:19:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 22 @ 66 updates, score 0.42) (writing took 0.9617359936237335 seconds)
2023-11-04 10:19:49 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-11-04 10:19:49 | INFO | train | epoch 022 | loss 9.006 | nll_loss 8.76 | ppl 433.5 | wps 3938 | ups 1.53 | wpb 2565.7 | bsz 266.7 | num_updates 66 | lr 8.25e-06 | gnorm 2.555 | train_wall 1 | gb_free 46 | wall 52
2023-11-04 10:19:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:49 | INFO | fairseq.trainer | begin training epoch 23
2023-11-04 10:19:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:49 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:19:49 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:50 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:50 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:50 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.988 | nll_loss 8.697 | ppl 414.87 | bleu 0.45 | wps 988.3 | wpb 566.5 | bsz 50 | num_updates 69 | best_bleu 0.69
2023-11-04 10:19:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 69 updates
2023-11-04 10:19:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 23 @ 69 updates, score 0.45) (writing took 0.9219829197973013 seconds)
2023-11-04 10:19:50 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-11-04 10:19:50 | INFO | train | epoch 023 | loss 8.954 | nll_loss 8.7 | ppl 415.81 | wps 4549.2 | ups 1.77 | wpb 2565.7 | bsz 266.7 | num_updates 69 | lr 8.625e-06 | gnorm 2.356 | train_wall 0 | gb_free 46 | wall 54
2023-11-04 10:19:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:50 | INFO | fairseq.trainer | begin training epoch 24
2023-11-04 10:19:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:51 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:19:51 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:51 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:51 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:51 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.954 | nll_loss 8.656 | ppl 403.32 | bleu 0.46 | wps 996.6 | wpb 566.5 | bsz 50 | num_updates 72 | best_bleu 0.69
2023-11-04 10:19:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 72 updates
2023-11-04 10:19:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 24 @ 72 updates, score 0.46) (writing took 0.94075190089643 seconds)
2023-11-04 10:19:52 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-11-04 10:19:52 | INFO | train | epoch 024 | loss 8.92 | nll_loss 8.66 | ppl 404.42 | wps 4474.3 | ups 1.74 | wpb 2565.7 | bsz 266.7 | num_updates 72 | lr 9e-06 | gnorm 2.184 | train_wall 0 | gb_free 45.8 | wall 55
2023-11-04 10:19:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:52 | INFO | fairseq.trainer | begin training epoch 25
2023-11-04 10:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:53 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:19:53 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:53 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:53 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:53 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.909 | nll_loss 8.606 | ppl 389.57 | bleu 0.46 | wps 873 | wpb 566.5 | bsz 50 | num_updates 75 | best_bleu 0.69
2023-11-04 10:19:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 75 updates
2023-11-04 10:19:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 25 @ 75 updates, score 0.46) (writing took 0.924164230003953 seconds)
2023-11-04 10:19:54 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-11-04 10:19:54 | INFO | train | epoch 025 | loss 8.878 | nll_loss 8.613 | ppl 391.49 | wps 4182.6 | ups 1.63 | wpb 2565.7 | bsz 266.7 | num_updates 75 | lr 9.375e-06 | gnorm 2.181 | train_wall 0 | gb_free 45.8 | wall 57
2023-11-04 10:19:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:54 | INFO | fairseq.trainer | begin training epoch 26
2023-11-04 10:19:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:55 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:55 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:55 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:55 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:55 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.845 | nll_loss 8.538 | ppl 371.76 | bleu 0.45 | wps 992.1 | wpb 566.5 | bsz 50 | num_updates 78 | best_bleu 0.69
2023-11-04 10:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 78 updates
2023-11-04 10:19:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 26 @ 78 updates, score 0.45) (writing took 0.912168275564909 seconds)
2023-11-04 10:19:56 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-11-04 10:19:56 | INFO | train | epoch 026 | loss 8.854 | nll_loss 8.586 | ppl 384.2 | wps 4636.1 | ups 1.81 | wpb 2565.7 | bsz 266.7 | num_updates 78 | lr 9.75e-06 | gnorm 2.125 | train_wall 0 | gb_free 45.8 | wall 59
2023-11-04 10:19:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:56 | INFO | fairseq.trainer | begin training epoch 27
2023-11-04 10:19:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:56 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:56 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:56 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:56 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:57 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.783 | nll_loss 8.473 | ppl 355.37 | bleu 0.46 | wps 895.9 | wpb 566.5 | bsz 50 | num_updates 81 | best_bleu 0.69
2023-11-04 10:19:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 81 updates
2023-11-04 10:19:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 27 @ 81 updates, score 0.46) (writing took 0.9255065713077784 seconds)
2023-11-04 10:19:57 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-11-04 10:19:57 | INFO | train | epoch 027 | loss 8.818 | nll_loss 8.547 | ppl 374.03 | wps 4394.5 | ups 1.71 | wpb 2565.7 | bsz 266.7 | num_updates 81 | lr 1.0125e-05 | gnorm 2.036 | train_wall 0 | gb_free 45.8 | wall 61
2023-11-04 10:19:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:57 | INFO | fairseq.trainer | begin training epoch 28
2023-11-04 10:19:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:19:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:19:58 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:58 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:19:58 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:19:58 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:19:58 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.726 | nll_loss 8.413 | ppl 340.93 | bleu 0.46 | wps 980.3 | wpb 566.5 | bsz 50 | num_updates 84 | best_bleu 0.69
2023-11-04 10:19:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 84 updates
2023-11-04 10:19:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:19:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 28 @ 84 updates, score 0.46) (writing took 0.9062398541718721 seconds)
2023-11-04 10:19:59 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-11-04 10:19:59 | INFO | train | epoch 028 | loss 8.791 | nll_loss 8.518 | ppl 366.49 | wps 4642.5 | ups 1.81 | wpb 2565.7 | bsz 266.7 | num_updates 84 | lr 1.05e-05 | gnorm 1.987 | train_wall 0 | gb_free 45.8 | wall 62
2023-11-04 10:19:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:19:59 | INFO | fairseq.trainer | begin training epoch 29
2023-11-04 10:19:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:00 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:00 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:00 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:00 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:00 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.681 | nll_loss 8.366 | ppl 329.88 | bleu 0.46 | wps 890.5 | wpb 566.5 | bsz 50 | num_updates 87 | best_bleu 0.69
2023-11-04 10:20:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 87 updates
2023-11-04 10:20:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 29 @ 87 updates, score 0.46) (writing took 0.9196127131581306 seconds)
2023-11-04 10:20:01 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-11-04 10:20:01 | INFO | train | epoch 029 | loss 8.769 | nll_loss 8.495 | ppl 360.73 | wps 4436.6 | ups 1.73 | wpb 2565.7 | bsz 266.7 | num_updates 87 | lr 1.0875e-05 | gnorm 1.963 | train_wall 0 | gb_free 45.8 | wall 64
2023-11-04 10:20:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:01 | INFO | fairseq.trainer | begin training epoch 30
2023-11-04 10:20:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:02 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:02 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:02 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:02 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:02 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.653 | nll_loss 8.333 | ppl 322.47 | bleu 0.47 | wps 988.1 | wpb 566.5 | bsz 50 | num_updates 90 | best_bleu 0.69
2023-11-04 10:20:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 90 updates
2023-11-04 10:20:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 30 @ 90 updates, score 0.47) (writing took 0.9157413318753242 seconds)
2023-11-04 10:20:03 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-11-04 10:20:03 | INFO | train | epoch 030 | loss 8.722 | nll_loss 8.442 | ppl 347.76 | wps 4589.6 | ups 1.79 | wpb 2565.7 | bsz 266.7 | num_updates 90 | lr 1.125e-05 | gnorm 1.924 | train_wall 0 | gb_free 46 | wall 66
2023-11-04 10:20:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:03 | INFO | fairseq.trainer | begin training epoch 31
2023-11-04 10:20:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:03 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:03 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:03 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:03 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:03 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.622 | nll_loss 8.298 | ppl 314.71 | bleu 0.46 | wps 1001.4 | wpb 566.5 | bsz 50 | num_updates 93 | best_bleu 0.69
2023-11-04 10:20:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 93 updates
2023-11-04 10:20:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 31 @ 93 updates, score 0.46) (writing took 0.988830491900444 seconds)
2023-11-04 10:20:04 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-11-04 10:20:04 | INFO | train | epoch 031 | loss 8.709 | nll_loss 8.427 | ppl 344.17 | wps 4364.5 | ups 1.7 | wpb 2565.7 | bsz 266.7 | num_updates 93 | lr 1.1625e-05 | gnorm 1.875 | train_wall 0 | gb_free 45.8 | wall 68
2023-11-04 10:20:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:04 | INFO | fairseq.trainer | begin training epoch 32
2023-11-04 10:20:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:05 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:05 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:05 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:05 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:05 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.589 | nll_loss 8.261 | ppl 306.73 | bleu 0.47 | wps 880.5 | wpb 566.5 | bsz 50 | num_updates 96 | best_bleu 0.69
2023-11-04 10:20:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 96 updates
2023-11-04 10:20:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 32 @ 96 updates, score 0.47) (writing took 0.9401560798287392 seconds)
2023-11-04 10:20:06 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-11-04 10:20:06 | INFO | train | epoch 032 | loss 8.666 | nll_loss 8.379 | ppl 332.88 | wps 4165.9 | ups 1.62 | wpb 2565.7 | bsz 266.7 | num_updates 96 | lr 1.2e-05 | gnorm 1.832 | train_wall 0 | gb_free 45.8 | wall 69
2023-11-04 10:20:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:06 | INFO | fairseq.trainer | begin training epoch 33
2023-11-04 10:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:07 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:07 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:07 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:07 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:07 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.556 | nll_loss 8.225 | ppl 299.14 | bleu 0.48 | wps 958.3 | wpb 566.5 | bsz 50 | num_updates 99 | best_bleu 0.69
2023-11-04 10:20:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 99 updates
2023-11-04 10:20:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 33 @ 99 updates, score 0.48) (writing took 0.9298834800720215 seconds)
2023-11-04 10:20:08 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-11-04 10:20:08 | INFO | train | epoch 033 | loss 8.627 | nll_loss 8.334 | ppl 322.74 | wps 4452.7 | ups 1.74 | wpb 2565.7 | bsz 266.7 | num_updates 99 | lr 1.2375e-05 | gnorm 1.777 | train_wall 0 | gb_free 45.8 | wall 71
2023-11-04 10:20:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:08 | INFO | fairseq.trainer | begin training epoch 34
2023-11-04 10:20:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:08 | INFO | train_inner | epoch 034:      1 / 3 loss=9.575, nll_loss=9.399, ppl=675.13, wps=3623.4, ups=1.41, wpb=2565.1, bsz=267.7, num_updates=100, lr=1.25e-05, gnorm=4.22, train_wall=14, gb_free=45.8, wall=71
2023-11-04 10:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:09 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:09 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:09 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:09 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:09 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.529 | nll_loss 8.193 | ppl 292.66 | bleu 0.49 | wps 962.5 | wpb 566.5 | bsz 50 | num_updates 102 | best_bleu 0.69
2023-11-04 10:20:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 102 updates
2023-11-04 10:20:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 34 @ 102 updates, score 0.49) (writing took 0.9299876485019922 seconds)
2023-11-04 10:20:10 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-11-04 10:20:10 | INFO | train | epoch 034 | loss 8.624 | nll_loss 8.331 | ppl 321.98 | wps 4463.5 | ups 1.74 | wpb 2565.7 | bsz 266.7 | num_updates 102 | lr 1.275e-05 | gnorm 1.775 | train_wall 0 | gb_free 45.8 | wall 73
2023-11-04 10:20:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:10 | INFO | fairseq.trainer | begin training epoch 35
2023-11-04 10:20:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:10 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:10 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:10 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:10 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:10 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.492 | nll_loss 8.154 | ppl 284.82 | bleu 0.48 | wps 926.6 | wpb 566.5 | bsz 50 | num_updates 105 | best_bleu 0.69
2023-11-04 10:20:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 105 updates
2023-11-04 10:20:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 35 @ 105 updates, score 0.48) (writing took 0.9358007200062275 seconds)
2023-11-04 10:20:11 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-11-04 10:20:11 | INFO | train | epoch 035 | loss 8.586 | nll_loss 8.289 | ppl 312.73 | wps 4210.1 | ups 1.64 | wpb 2565.7 | bsz 266.7 | num_updates 105 | lr 1.3125e-05 | gnorm 1.686 | train_wall 0 | gb_free 45.8 | wall 75
2023-11-04 10:20:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:11 | INFO | fairseq.trainer | begin training epoch 36
2023-11-04 10:20:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:12 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:12 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:12 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:12 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:12 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.454 | nll_loss 8.114 | ppl 277 | bleu 0.48 | wps 593.5 | wpb 566.5 | bsz 50 | num_updates 108 | best_bleu 0.69
2023-11-04 10:20:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 108 updates
2023-11-04 10:20:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 36 @ 108 updates, score 0.48) (writing took 0.9127972833812237 seconds)
2023-11-04 10:20:13 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-11-04 10:20:13 | INFO | train | epoch 036 | loss 8.567 | nll_loss 8.267 | ppl 308.13 | wps 4487.3 | ups 1.75 | wpb 2565.7 | bsz 266.7 | num_updates 108 | lr 1.35e-05 | gnorm 1.672 | train_wall 0 | gb_free 45.8 | wall 76
2023-11-04 10:20:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:13 | INFO | fairseq.trainer | begin training epoch 37
2023-11-04 10:20:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:14 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:20:14 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:14 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:14 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:14 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.432 | nll_loss 8.087 | ppl 271.87 | bleu 0.5 | wps 981.7 | wpb 566.5 | bsz 50 | num_updates 111 | best_bleu 0.69
2023-11-04 10:20:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 111 updates
2023-11-04 10:20:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 37 @ 111 updates, score 0.5) (writing took 0.9181523732841015 seconds)
2023-11-04 10:20:15 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-11-04 10:20:15 | INFO | train | epoch 037 | loss 8.547 | nll_loss 8.245 | ppl 303.48 | wps 4548.1 | ups 1.77 | wpb 2565.7 | bsz 266.7 | num_updates 111 | lr 1.3875e-05 | gnorm 1.632 | train_wall 0 | gb_free 45.8 | wall 78
2023-11-04 10:20:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:15 | INFO | fairseq.trainer | begin training epoch 38
2023-11-04 10:20:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:16 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:20:16 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:16 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:16 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:16 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.414 | nll_loss 8.064 | ppl 267.7 | bleu 0.51 | wps 790.3 | wpb 566.5 | bsz 50 | num_updates 114 | best_bleu 0.69
2023-11-04 10:20:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 114 updates
2023-11-04 10:20:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 38 @ 114 updates, score 0.51) (writing took 0.9247519224882126 seconds)
2023-11-04 10:20:17 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-11-04 10:20:17 | INFO | train | epoch 038 | loss 8.51 | nll_loss 8.202 | ppl 294.49 | wps 4153.7 | ups 1.62 | wpb 2565.7 | bsz 266.7 | num_updates 114 | lr 1.425e-05 | gnorm 1.601 | train_wall 0 | gb_free 45.8 | wall 80
2023-11-04 10:20:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:17 | INFO | fairseq.trainer | begin training epoch 39
2023-11-04 10:20:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:17 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:20:17 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:17 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:17 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:17 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.39 | nll_loss 8.037 | ppl 262.67 | bleu 0.49 | wps 956.3 | wpb 566.5 | bsz 50 | num_updates 117 | best_bleu 0.69
2023-11-04 10:20:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 117 updates
2023-11-04 10:20:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 39 @ 117 updates, score 0.49) (writing took 0.9249744433909655 seconds)
2023-11-04 10:20:18 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-11-04 10:20:18 | INFO | train | epoch 039 | loss 8.496 | nll_loss 8.185 | ppl 291.1 | wps 4576 | ups 1.78 | wpb 2565.7 | bsz 266.7 | num_updates 117 | lr 1.4625e-05 | gnorm 1.525 | train_wall 0 | gb_free 46 | wall 82
2023-11-04 10:20:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:18 | INFO | fairseq.trainer | begin training epoch 40
2023-11-04 10:20:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:19 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:20:19 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:19 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:19 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:19 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.34 | nll_loss 7.985 | ppl 253.4 | bleu 0.49 | wps 931.2 | wpb 566.5 | bsz 50 | num_updates 120 | best_bleu 0.69
2023-11-04 10:20:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 120 updates
2023-11-04 10:20:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 40 @ 120 updates, score 0.49) (writing took 0.9314257334917784 seconds)
2023-11-04 10:20:20 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-11-04 10:20:20 | INFO | train | epoch 040 | loss 8.462 | nll_loss 8.149 | ppl 283.77 | wps 4250.1 | ups 1.66 | wpb 2565.7 | bsz 266.7 | num_updates 120 | lr 1.5e-05 | gnorm 1.508 | train_wall 0 | gb_free 45.8 | wall 83
2023-11-04 10:20:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:20 | INFO | fairseq.trainer | begin training epoch 41
2023-11-04 10:20:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:21 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:20:21 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:21 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:21 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:21 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.313 | nll_loss 7.955 | ppl 248.07 | bleu 0.52 | wps 995.5 | wpb 566.5 | bsz 50 | num_updates 123 | best_bleu 0.69
2023-11-04 10:20:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 123 updates
2023-11-04 10:20:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 41 @ 123 updates, score 0.52) (writing took 0.9232763964682817 seconds)
2023-11-04 10:20:22 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-11-04 10:20:22 | INFO | train | epoch 041 | loss 8.448 | nll_loss 8.134 | ppl 281 | wps 4495.4 | ups 1.75 | wpb 2565.7 | bsz 266.7 | num_updates 123 | lr 1.5375e-05 | gnorm 1.433 | train_wall 0 | gb_free 46 | wall 85
2023-11-04 10:20:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:22 | INFO | fairseq.trainer | begin training epoch 42
2023-11-04 10:20:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:23 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:20:23 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:23 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:23 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:23 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.287 | nll_loss 7.926 | ppl 243.17 | bleu 0.54 | wps 1000.7 | wpb 566.5 | bsz 50 | num_updates 126 | best_bleu 0.69
2023-11-04 10:20:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 126 updates
2023-11-04 10:20:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 42 @ 126 updates, score 0.54) (writing took 0.965836713090539 seconds)
2023-11-04 10:20:24 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-11-04 10:20:24 | INFO | train | epoch 042 | loss 8.407 | nll_loss 8.088 | ppl 272.03 | wps 4372.9 | ups 1.7 | wpb 2565.7 | bsz 266.7 | num_updates 126 | lr 1.575e-05 | gnorm 1.383 | train_wall 0 | gb_free 45.8 | wall 87
2023-11-04 10:20:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:24 | INFO | fairseq.trainer | begin training epoch 43
2023-11-04 10:20:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:25 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:20:25 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:25 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:25 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:25 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.273 | nll_loss 7.907 | ppl 239.99 | bleu 0.54 | wps 822.9 | wpb 566.5 | bsz 50 | num_updates 129 | best_bleu 0.69
2023-11-04 10:20:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 129 updates
2023-11-04 10:20:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 43 @ 129 updates, score 0.54) (writing took 0.976628826931119 seconds)
2023-11-04 10:20:26 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-11-04 10:20:26 | INFO | train | epoch 043 | loss 8.383 | nll_loss 8.06 | ppl 266.8 | wps 3953.4 | ups 1.54 | wpb 2565.7 | bsz 266.7 | num_updates 129 | lr 1.6125e-05 | gnorm 1.332 | train_wall 0 | gb_free 45.8 | wall 89
2023-11-04 10:20:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:26 | INFO | fairseq.trainer | begin training epoch 44
2023-11-04 10:20:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:26 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:20:26 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:26 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:20:26 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:26 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.264 | nll_loss 7.893 | ppl 237.65 | bleu 0.54 | wps 928.7 | wpb 566.5 | bsz 50 | num_updates 132 | best_bleu 0.69
2023-11-04 10:20:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 132 updates
2023-11-04 10:20:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 44 @ 132 updates, score 0.54) (writing took 0.9496457781642675 seconds)
2023-11-04 10:20:27 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-11-04 10:20:27 | INFO | train | epoch 044 | loss 8.363 | nll_loss 8.037 | ppl 262.57 | wps 4455 | ups 1.74 | wpb 2565.7 | bsz 266.7 | num_updates 132 | lr 1.65e-05 | gnorm 1.389 | train_wall 0 | gb_free 46 | wall 91
2023-11-04 10:20:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:27 | INFO | fairseq.trainer | begin training epoch 45
2023-11-04 10:20:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:28 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:20:28 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:28 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:20:28 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:28 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.229 | nll_loss 7.855 | ppl 231.53 | bleu 0.58 | wps 1002 | wpb 566.5 | bsz 50 | num_updates 135 | best_bleu 0.69
2023-11-04 10:20:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 135 updates
2023-11-04 10:20:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 45 @ 135 updates, score 0.58) (writing took 1.0177064631134272 seconds)
2023-11-04 10:20:29 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-11-04 10:20:29 | INFO | train | epoch 045 | loss 8.336 | nll_loss 8.004 | ppl 256.79 | wps 4191.9 | ups 1.63 | wpb 2565.7 | bsz 266.7 | num_updates 135 | lr 1.6875e-05 | gnorm 1.327 | train_wall 0 | gb_free 45.8 | wall 92
2023-11-04 10:20:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:29 | INFO | fairseq.trainer | begin training epoch 46
2023-11-04 10:20:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:30 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:20:30 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:30 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:20:30 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:30 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.198 | nll_loss 7.821 | ppl 226.19 | bleu 0.6 | wps 864.8 | wpb 566.5 | bsz 50 | num_updates 138 | best_bleu 0.69
2023-11-04 10:20:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 138 updates
2023-11-04 10:20:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 46 @ 138 updates, score 0.6) (writing took 0.925447141751647 seconds)
2023-11-04 10:20:31 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-11-04 10:20:31 | INFO | train | epoch 046 | loss 8.305 | nll_loss 7.97 | ppl 250.73 | wps 4147.8 | ups 1.62 | wpb 2565.7 | bsz 266.7 | num_updates 138 | lr 1.725e-05 | gnorm 1.251 | train_wall 0 | gb_free 46 | wall 94
2023-11-04 10:20:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:31 | INFO | fairseq.trainer | begin training epoch 47
2023-11-04 10:20:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:32 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:20:32 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:32 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:20:32 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:32 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.158 | nll_loss 7.779 | ppl 219.69 | bleu 0.64 | wps 995.5 | wpb 566.5 | bsz 50 | num_updates 141 | best_bleu 0.69
2023-11-04 10:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 141 updates
2023-11-04 10:20:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 47 @ 141 updates, score 0.64) (writing took 0.9071824997663498 seconds)
2023-11-04 10:20:33 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-11-04 10:20:33 | INFO | train | epoch 047 | loss 8.288 | nll_loss 7.952 | ppl 247.68 | wps 4617.4 | ups 1.8 | wpb 2565.7 | bsz 266.7 | num_updates 141 | lr 1.7625e-05 | gnorm 1.272 | train_wall 0 | gb_free 45.8 | wall 96
2023-11-04 10:20:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:33 | INFO | fairseq.trainer | begin training epoch 48
2023-11-04 10:20:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:33 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:20:33 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:33 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:20:33 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:33 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.148 | nll_loss 7.764 | ppl 217.31 | bleu 0.63 | wps 993.9 | wpb 566.5 | bsz 50 | num_updates 144 | best_bleu 0.69
2023-11-04 10:20:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 144 updates
2023-11-04 10:20:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 48 @ 144 updates, score 0.63) (writing took 1.0125573612749577 seconds)
2023-11-04 10:20:35 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-11-04 10:20:35 | INFO | train | epoch 048 | loss 8.26 | nll_loss 7.921 | ppl 242.36 | wps 4253.2 | ups 1.66 | wpb 2565.7 | bsz 266.7 | num_updates 144 | lr 1.8e-05 | gnorm 1.279 | train_wall 0 | gb_free 46 | wall 98
2023-11-04 10:20:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:35 | INFO | fairseq.trainer | begin training epoch 49
2023-11-04 10:20:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:35 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:20:35 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:35 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:20:35 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:35 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.138 | nll_loss 7.748 | ppl 214.98 | bleu 0.59 | wps 631.5 | wpb 566.5 | bsz 50 | num_updates 147 | best_bleu 0.69
2023-11-04 10:20:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 147 updates
2023-11-04 10:20:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 49 @ 147 updates, score 0.59) (writing took 0.9313488248735666 seconds)
2023-11-04 10:20:36 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-11-04 10:20:36 | INFO | train | epoch 049 | loss 8.234 | nll_loss 7.89 | ppl 237.16 | wps 4271.9 | ups 1.67 | wpb 2565.7 | bsz 266.7 | num_updates 147 | lr 1.8375e-05 | gnorm 1.213 | train_wall 0 | gb_free 45.8 | wall 100
2023-11-04 10:20:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:36 | INFO | fairseq.trainer | begin training epoch 50
2023-11-04 10:20:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:37 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:20:37 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:37 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:20:37 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:37 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.117 | nll_loss 7.722 | ppl 211.18 | bleu 0.53 | wps 1098.6 | wpb 566.5 | bsz 50 | num_updates 150 | best_bleu 0.69
2023-11-04 10:20:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 150 updates
2023-11-04 10:20:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 50 @ 150 updates, score 0.53) (writing took 0.9846342913806438 seconds)
2023-11-04 10:20:38 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-11-04 10:20:38 | INFO | train | epoch 050 | loss 8.191 | nll_loss 7.84 | ppl 229.08 | wps 4411.1 | ups 1.72 | wpb 2565.7 | bsz 266.7 | num_updates 150 | lr 1.875e-05 | gnorm 1.26 | train_wall 0 | gb_free 46 | wall 101
2023-11-04 10:20:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:20:38 | INFO | fairseq.trainer | begin training epoch 51
2023-11-04 10:20:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:20:39 | INFO | fairseq.tasks.translation | example hypothesis: the
2023-11-04 10:20:39 | INFO | fairseq.tasks.translation | example reference: keelalaglolimakizes the hofoboflofrikul the chahedikibihap
2023-11-04 10:20:39 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:20:39 | INFO | fairseq.tasks.translation | example reference: bileechameelikotizes the frokifohamihor the buhuhudimogluf
2023-11-04 10:20:39 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.088 | nll_loss 7.69 | ppl 206.51 | bleu 0.46 | wps 1091.3 | wpb 566.5 | bsz 50 | num_updates 153 | best_bleu 0.69
2023-11-04 10:20:39 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 40 runs
2023-11-04 10:20:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 153 updates
2023-11-04 10:20:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:20:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_VOS_1.0k/checkpoints/checkpoint_last.pt (epoch 51 @ 153 updates, score 0.46) (writing took 0.9303287845104933 seconds)
2023-11-04 10:20:40 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-11-04 10:20:40 | INFO | train | epoch 051 | loss 8.177 | nll_loss 7.824 | ppl 226.53 | wps 3581.6 | ups 1.4 | wpb 2565.7 | bsz 266.7 | num_updates 153 | lr 1.9125e-05 | gnorm 1.212 | train_wall 1 | gb_free 45.8 | wall 104
2023-11-04 10:20:40 | INFO | fairseq_cli.train | done training in 103.5 seconds
learn_bpe.py on /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/data/train.en-it...
apply_bpe.py to train.en...
apply_bpe.py to dev.en...
apply_bpe.py to test.en...
apply_bpe.py to train.it...
apply_bpe.py to dev.it...
apply_bpe.py to test.it...
2023-11-04 10:21:13 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/tensorboard_logs/', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1000, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 40, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir='/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/tensorboard_logs/', wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='chrf', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_iwslt_de_en', max_epoch=1000, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=40, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/data-bin', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_attention_heads=4, encoder_layers=6, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_iwslt_de_en'), 'task': {'_name': 'translation', 'data': '/mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'chrf'}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-11-04 10:21:13 | INFO | fairseq.tasks.translation | [en] dictionary: 1264 types
2023-11-04 10:21:13 | INFO | fairseq.tasks.translation | [it] dictionary: 1256 types
2023-11-04 10:21:14 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(1264, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(1256, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=1256, bias=False)
  )
)
2023-11-04 10:21:14 | INFO | fairseq_cli.train | task: TranslationTask
2023-11-04 10:21:14 | INFO | fairseq_cli.train | model: TransformerModel
2023-11-04 10:21:14 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2023-11-04 10:21:14 | INFO | fairseq_cli.train | num. shared model params: 45,437,952 (num. trained: 45,437,952)
2023-11-04 10:21:14 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-11-04 10:21:14 | INFO | fairseq.data.data_utils | loaded 100 examples from: /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/data-bin/valid.en-it.en
2023-11-04 10:21:14 | INFO | fairseq.data.data_utils | loaded 100 examples from: /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/data-bin/valid.en-it.it
2023-11-04 10:21:14 | INFO | fairseq.tasks.translation | /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/data-bin valid en-it 100 examples
2023-11-04 10:21:16 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2023-11-04 10:21:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-11-04 10:21:16 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 47.544 GB ; name = NVIDIA RTX A6000                        
2023-11-04 10:21:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-11-04 10:21:16 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2023-11-04 10:21:16 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None
2023-11-04 10:21:16 | INFO | fairseq.trainer | Preparing to load checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:16 | INFO | fairseq.trainer | No existing checkpoint found /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:16 | INFO | fairseq.trainer | loading train data for epoch 1
2023-11-04 10:21:16 | INFO | fairseq.data.data_utils | loaded 800 examples from: /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/data-bin/train.en-it.en
2023-11-04 10:21:16 | INFO | fairseq.data.data_utils | loaded 800 examples from: /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/data-bin/train.en-it.it
2023-11-04 10:21:16 | INFO | fairseq.tasks.translation | /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/data-bin train en-it 800 examples
2023-11-04 10:21:16 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2023-11-04 10:21:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:16 | INFO | fairseq.trainer | begin training epoch 1
2023-11-04 10:21:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:18 | INFO | fairseq.tasks.translation | example hypothesis: lugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglu
2023-11-04 10:21:18 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:19 | INFO | fairseq.tasks.translation | example hypothesis: bukabukabukabukabukaluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglu
2023-11-04 10:21:19 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:19 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.517 | nll_loss 10.464 | ppl 1412.6 | bleu 0 | wps 225.2 | wpb 573.5 | bsz 50 | num_updates 3
2023-11-04 10:21:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 3 updates
2023-11-04 10:21:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 1 @ 3 updates, score 0.0) (writing took 1.2401435505598783 seconds)
2023-11-04 10:21:20 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-11-04 10:21:20 | INFO | train | epoch 001 | loss 10.72 | nll_loss 10.689 | ppl 1650.33 | wps 2052.3 | ups 0.8 | wpb 2560 | bsz 266.7 | num_updates 3 | lr 3.75e-07 | gnorm 8.161 | train_wall 2 | gb_free 45.8 | wall 4
2023-11-04 10:21:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:20 | INFO | fairseq.trainer | begin training epoch 2
2023-11-04 10:21:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:21 | INFO | fairseq.tasks.translation | example hypothesis: lugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglu
2023-11-04 10:21:21 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:22 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the luglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglu
2023-11-04 10:21:22 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:22 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.473 | nll_loss 10.415 | ppl 1365.51 | bleu 0.17 | wps 181.1 | wpb 573.5 | bsz 50 | num_updates 6 | best_bleu 0.17
2023-11-04 10:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 6 updates
2023-11-04 10:21:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 2 @ 6 updates, score 0.17) (writing took 1.4031635783612728 seconds)
2023-11-04 10:21:23 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-11-04 10:21:23 | INFO | train | epoch 002 | loss 10.696 | nll_loss 10.661 | ppl 1619.45 | wps 2690.2 | ups 1.05 | wpb 2560 | bsz 266.7 | num_updates 6 | lr 7.5e-07 | gnorm 8.152 | train_wall 0 | gb_free 45.9 | wall 7
2023-11-04 10:21:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:23 | INFO | fairseq.trainer | begin training epoch 3
2023-11-04 10:21:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:24 | INFO | fairseq.tasks.translation | example hypothesis: lugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglulugluluglu
2023-11-04 10:21:24 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:25 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the
2023-11-04 10:21:25 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:25 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.399 | nll_loss 10.332 | ppl 1288.84 | bleu 0.22 | wps 202.8 | wpb 573.5 | bsz 50 | num_updates 9 | best_bleu 0.22
2023-11-04 10:21:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 9 updates
2023-11-04 10:21:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 3 @ 9 updates, score 0.22) (writing took 1.3826666045933962 seconds)
2023-11-04 10:21:26 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-11-04 10:21:26 | INFO | train | epoch 003 | loss 10.673 | nll_loss 10.635 | ppl 1590.5 | wps 2540.4 | ups 0.99 | wpb 2560 | bsz 266.7 | num_updates 9 | lr 1.125e-06 | gnorm 8.076 | train_wall 0 | gb_free 45.9 | wall 10
2023-11-04 10:21:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:26 | INFO | fairseq.trainer | begin training epoch 4
2023-11-04 10:21:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:27 | INFO | fairseq.tasks.translation | example hypothesis: lugluluglulugluluglulugluluglu
2023-11-04 10:21:27 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:28 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the
2023-11-04 10:21:28 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:28 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.297 | nll_loss 10.219 | ppl 1191.58 | bleu 0.19 | wps 177.7 | wpb 573.5 | bsz 50 | num_updates 12 | best_bleu 0.22
2023-11-04 10:21:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 12 updates
2023-11-04 10:21:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 4 @ 12 updates, score 0.19) (writing took 0.8432558383792639 seconds)
2023-11-04 10:21:28 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-11-04 10:21:28 | INFO | train | epoch 004 | loss 10.585 | nll_loss 10.538 | ppl 1486.62 | wps 3160.9 | ups 1.23 | wpb 2560 | bsz 266.7 | num_updates 12 | lr 1.5e-06 | gnorm 7.972 | train_wall 0 | gb_free 45.9 | wall 12
2023-11-04 10:21:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:28 | INFO | fairseq.trainer | begin training epoch 5
2023-11-04 10:21:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:29 | INFO | fairseq.tasks.translation | example hypothesis: luglulugluluglulugluluglu
2023-11-04 10:21:29 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:30 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:21:30 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:30 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.178 | nll_loss 10.084 | ppl 1085.25 | bleu 0.14 | wps 158 | wpb 573.5 | bsz 50 | num_updates 15 | best_bleu 0.22
2023-11-04 10:21:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 15 updates
2023-11-04 10:21:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 5 @ 15 updates, score 0.14) (writing took 0.8351283483207226 seconds)
2023-11-04 10:21:31 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-11-04 10:21:31 | INFO | train | epoch 005 | loss 10.473 | nll_loss 10.413 | ppl 1363.45 | wps 3281.8 | ups 1.28 | wpb 2560 | bsz 266.7 | num_updates 15 | lr 1.875e-06 | gnorm 7.764 | train_wall 0 | gb_free 45.9 | wall 15
2023-11-04 10:21:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:31 | INFO | fairseq.trainer | begin training epoch 6
2023-11-04 10:21:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:32 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:32 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:32 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:21:32 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:32 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.055 | nll_loss 9.943 | ppl 984.45 | bleu 0.29 | wps 964.3 | wpb 573.5 | bsz 50 | num_updates 18 | best_bleu 0.29
2023-11-04 10:21:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 18 updates
2023-11-04 10:21:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 6 @ 18 updates, score 0.29) (writing took 1.4013056736439466 seconds)
2023-11-04 10:21:33 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-11-04 10:21:33 | INFO | train | epoch 006 | loss 10.343 | nll_loss 10.268 | ppl 1233.2 | wps 3152.6 | ups 1.23 | wpb 2560 | bsz 266.7 | num_updates 18 | lr 2.25e-06 | gnorm 7.417 | train_wall 0 | gb_free 45.8 | wall 17
2023-11-04 10:21:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:33 | INFO | fairseq.trainer | begin training epoch 7
2023-11-04 10:21:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:34 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:34 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:34 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:21:34 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:34 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.955 | nll_loss 9.823 | ppl 905.81 | bleu 0.42 | wps 950.5 | wpb 573.5 | bsz 50 | num_updates 21 | best_bleu 0.42
2023-11-04 10:21:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 21 updates
2023-11-04 10:21:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 7 @ 21 updates, score 0.42) (writing took 1.3806808553636074 seconds)
2023-11-04 10:21:35 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-11-04 10:21:35 | INFO | train | epoch 007 | loss 10.215 | nll_loss 10.125 | ppl 1116.52 | wps 3584.1 | ups 1.4 | wpb 2560 | bsz 266.7 | num_updates 21 | lr 2.625e-06 | gnorm 6.929 | train_wall 0 | gb_free 45.8 | wall 19
2023-11-04 10:21:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:35 | INFO | fairseq.trainer | begin training epoch 8
2023-11-04 10:21:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:36 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:36 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:36 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:21:36 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:36 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.914 | nll_loss 9.761 | ppl 867.4 | bleu 0.46 | wps 952.4 | wpb 573.5 | bsz 50 | num_updates 24 | best_bleu 0.46
2023-11-04 10:21:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 24 updates
2023-11-04 10:21:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 8 @ 24 updates, score 0.46) (writing took 1.3850549682974815 seconds)
2023-11-04 10:21:37 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-11-04 10:21:38 | INFO | train | epoch 008 | loss 10.092 | nll_loss 9.985 | ppl 1013.2 | wps 3528 | ups 1.38 | wpb 2560 | bsz 266.7 | num_updates 24 | lr 3e-06 | gnorm 6.099 | train_wall 0 | gb_free 45.9 | wall 21
2023-11-04 10:21:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:38 | INFO | fairseq.trainer | begin training epoch 9
2023-11-04 10:21:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:38 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:38 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:38 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:21:38 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:38 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.964 | nll_loss 9.789 | ppl 884.9 | bleu 0.48 | wps 942.4 | wpb 573.5 | bsz 50 | num_updates 27 | best_bleu 0.48
2023-11-04 10:21:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 27 updates
2023-11-04 10:21:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 9 @ 27 updates, score 0.48) (writing took 1.435757027938962 seconds)
2023-11-04 10:21:40 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-11-04 10:21:40 | INFO | train | epoch 009 | loss 9.938 | nll_loss 9.809 | ppl 897.09 | wps 3381.6 | ups 1.32 | wpb 2560 | bsz 266.7 | num_updates 27 | lr 3.375e-06 | gnorm 5.024 | train_wall 0 | gb_free 45.8 | wall 24
2023-11-04 10:21:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:40 | INFO | fairseq.trainer | begin training epoch 10
2023-11-04 10:21:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:41 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:21:41 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:41 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:41 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:41 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.091 | nll_loss 9.897 | ppl 953.77 | bleu 0.51 | wps 933.3 | wpb 573.5 | bsz 50 | num_updates 30 | best_bleu 0.51
2023-11-04 10:21:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 30 updates
2023-11-04 10:21:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 10 @ 30 updates, score 0.51) (writing took 1.5139636360108852 seconds)
2023-11-04 10:21:42 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-11-04 10:21:42 | INFO | train | epoch 010 | loss 9.842 | nll_loss 9.694 | ppl 828.04 | wps 3253.2 | ups 1.27 | wpb 2560 | bsz 266.7 | num_updates 30 | lr 3.75e-06 | gnorm 4.111 | train_wall 0 | gb_free 45.8 | wall 26
2023-11-04 10:21:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:42 | INFO | fairseq.trainer | begin training epoch 11
2023-11-04 10:21:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:43 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:21:43 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:43 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:43 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:43 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.217 | nll_loss 10.007 | ppl 1028.76 | bleu 0.55 | wps 845.8 | wpb 573.5 | bsz 50 | num_updates 33 | best_bleu 0.55
2023-11-04 10:21:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 33 updates
2023-11-04 10:21:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 11 @ 33 updates, score 0.55) (writing took 1.3802844565361738 seconds)
2023-11-04 10:21:45 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-11-04 10:21:45 | INFO | train | epoch 011 | loss 9.766 | nll_loss 9.6 | ppl 775.91 | wps 3134.9 | ups 1.22 | wpb 2560 | bsz 266.7 | num_updates 33 | lr 4.125e-06 | gnorm 4.065 | train_wall 1 | gb_free 45.9 | wall 28
2023-11-04 10:21:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:45 | INFO | fairseq.trainer | begin training epoch 12
2023-11-04 10:21:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:45 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:21:45 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:46 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:21:46 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:46 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.222 | nll_loss 10.001 | ppl 1024.56 | bleu 0.57 | wps 740.5 | wpb 573.5 | bsz 50 | num_updates 36 | best_bleu 0.57
2023-11-04 10:21:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 36 updates
2023-11-04 10:21:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:21:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 12 @ 36 updates, score 0.57) (writing took 1.4249991849064827 seconds)
2023-11-04 10:21:47 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-11-04 10:21:47 | INFO | train | epoch 012 | loss 9.687 | nll_loss 9.504 | ppl 726.07 | wps 3225.3 | ups 1.26 | wpb 2560 | bsz 266.7 | num_updates 36 | lr 4.5e-06 | gnorm 4.117 | train_wall 0 | gb_free 45.9 | wall 31
2023-11-04 10:21:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:47 | INFO | fairseq.trainer | begin training epoch 13
2023-11-04 10:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:48 | INFO | fairseq.tasks.translation | example hypothesis: the the
2023-11-04 10:21:48 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:48 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:21:48 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:48 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.064 | nll_loss 9.836 | ppl 914.18 | bleu 0.53 | wps 950 | wpb 573.5 | bsz 50 | num_updates 39 | best_bleu 0.57
2023-11-04 10:21:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 39 updates
2023-11-04 10:21:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 13 @ 39 updates, score 0.53) (writing took 0.83924082480371 seconds)
2023-11-04 10:21:49 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-11-04 10:21:49 | INFO | train | epoch 013 | loss 9.643 | nll_loss 9.452 | ppl 700.2 | wps 4771.4 | ups 1.86 | wpb 2560 | bsz 266.7 | num_updates 39 | lr 4.875e-06 | gnorm 4.265 | train_wall 0 | gb_free 45.8 | wall 32
2023-11-04 10:21:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:49 | INFO | fairseq.trainer | begin training epoch 14
2023-11-04 10:21:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:49 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:21:49 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:49 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:49 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:49 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.818 | nll_loss 9.589 | ppl 770.32 | bleu 0.51 | wps 864.6 | wpb 573.5 | bsz 50 | num_updates 42 | best_bleu 0.57
2023-11-04 10:21:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 42 updates
2023-11-04 10:21:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 14 @ 42 updates, score 0.51) (writing took 0.8417720068246126 seconds)
2023-11-04 10:21:50 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-11-04 10:21:50 | INFO | train | epoch 014 | loss 9.567 | nll_loss 9.371 | ppl 662.27 | wps 4580 | ups 1.79 | wpb 2560 | bsz 266.7 | num_updates 42 | lr 5.25e-06 | gnorm 3.962 | train_wall 0 | gb_free 45.8 | wall 34
2023-11-04 10:21:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:50 | INFO | fairseq.trainer | begin training epoch 15
2023-11-04 10:21:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:51 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:51 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:51 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:51 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:51 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.589 | nll_loss 9.36 | ppl 657.19 | bleu 0.51 | wps 930.9 | wpb 573.5 | bsz 50 | num_updates 45 | best_bleu 0.57
2023-11-04 10:21:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 45 updates
2023-11-04 10:21:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 15 @ 45 updates, score 0.51) (writing took 0.8309504389762878 seconds)
2023-11-04 10:21:52 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-11-04 10:21:52 | INFO | train | epoch 015 | loss 9.485 | nll_loss 9.288 | ppl 625.18 | wps 4629.1 | ups 1.81 | wpb 2560 | bsz 266.7 | num_updates 45 | lr 5.625e-06 | gnorm 3.329 | train_wall 0 | gb_free 45.8 | wall 36
2023-11-04 10:21:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:52 | INFO | fairseq.trainer | begin training epoch 16
2023-11-04 10:21:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:53 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:53 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:53 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:53 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:53 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.423 | nll_loss 9.192 | ppl 584.88 | bleu 0.53 | wps 957 | wpb 573.5 | bsz 50 | num_updates 48 | best_bleu 0.57
2023-11-04 10:21:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 48 updates
2023-11-04 10:21:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 16 @ 48 updates, score 0.53) (writing took 0.8401888366788626 seconds)
2023-11-04 10:21:54 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-11-04 10:21:54 | INFO | train | epoch 016 | loss 9.417 | nll_loss 9.218 | ppl 595.68 | wps 4578.6 | ups 1.79 | wpb 2560 | bsz 266.7 | num_updates 48 | lr 6e-06 | gnorm 3.01 | train_wall 0 | gb_free 45.8 | wall 37
2023-11-04 10:21:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:54 | INFO | fairseq.trainer | begin training epoch 17
2023-11-04 10:21:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:54 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:54 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:55 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:21:55 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:55 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.31 | nll_loss 9.076 | ppl 539.68 | bleu 0.51 | wps 771.2 | wpb 573.5 | bsz 50 | num_updates 51 | best_bleu 0.57
2023-11-04 10:21:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 51 updates
2023-11-04 10:21:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 17 @ 51 updates, score 0.51) (writing took 0.8300404734909534 seconds)
2023-11-04 10:21:55 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-11-04 10:21:55 | INFO | train | epoch 017 | loss 9.345 | nll_loss 9.143 | ppl 565.4 | wps 4338.9 | ups 1.69 | wpb 2560 | bsz 266.7 | num_updates 51 | lr 6.375e-06 | gnorm 2.994 | train_wall 0 | gb_free 45.9 | wall 39
2023-11-04 10:21:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:55 | INFO | fairseq.trainer | begin training epoch 18
2023-11-04 10:21:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:56 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:21:56 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:56 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:21:56 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:56 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.234 | nll_loss 8.993 | ppl 509.59 | bleu 0.47 | wps 953 | wpb 573.5 | bsz 50 | num_updates 54 | best_bleu 0.57
2023-11-04 10:21:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 54 updates
2023-11-04 10:21:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 18 @ 54 updates, score 0.47) (writing took 0.8281164281070232 seconds)
2023-11-04 10:21:57 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-11-04 10:21:57 | INFO | train | epoch 018 | loss 9.287 | nll_loss 9.081 | ppl 541.39 | wps 4817.5 | ups 1.88 | wpb 2560 | bsz 266.7 | num_updates 54 | lr 6.75e-06 | gnorm 3.092 | train_wall 0 | gb_free 45.8 | wall 41
2023-11-04 10:21:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:57 | INFO | fairseq.trainer | begin training epoch 19
2023-11-04 10:21:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:21:58 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:21:58 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:21:58 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:21:58 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:21:58 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.192 | nll_loss 8.942 | ppl 491.89 | bleu 0.46 | wps 871.8 | wpb 573.5 | bsz 50 | num_updates 57 | best_bleu 0.57
2023-11-04 10:21:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 57 updates
2023-11-04 10:21:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:21:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 19 @ 57 updates, score 0.46) (writing took 0.8372867871075869 seconds)
2023-11-04 10:21:59 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-11-04 10:21:59 | INFO | train | epoch 019 | loss 9.22 | nll_loss 9.005 | ppl 513.85 | wps 4558.4 | ups 1.78 | wpb 2560 | bsz 266.7 | num_updates 57 | lr 7.125e-06 | gnorm 2.964 | train_wall 0 | gb_free 45.9 | wall 43
2023-11-04 10:21:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:21:59 | INFO | fairseq.trainer | begin training epoch 20
2023-11-04 10:21:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:21:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:00 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:22:00 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:00 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:00 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:00 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.171 | nll_loss 8.91 | ppl 480.87 | bleu 0.45 | wps 793.7 | wpb 573.5 | bsz 50 | num_updates 60 | best_bleu 0.57
2023-11-04 10:22:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 60 updates
2023-11-04 10:22:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 20 @ 60 updates, score 0.45) (writing took 0.8381263762712479 seconds)
2023-11-04 10:22:00 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-11-04 10:22:00 | INFO | train | epoch 020 | loss 9.172 | nll_loss 8.949 | ppl 494.17 | wps 4271.8 | ups 1.67 | wpb 2560 | bsz 266.7 | num_updates 60 | lr 7.5e-06 | gnorm 2.709 | train_wall 0 | gb_free 45.8 | wall 44
2023-11-04 10:22:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:01 | INFO | fairseq.trainer | begin training epoch 21
2023-11-04 10:22:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:01 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:22:01 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:01 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:22:01 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:01 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.14 | nll_loss 8.869 | ppl 467.61 | bleu 0.45 | wps 944.1 | wpb 573.5 | bsz 50 | num_updates 63 | best_bleu 0.57
2023-11-04 10:22:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 63 updates
2023-11-04 10:22:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 21 @ 63 updates, score 0.45) (writing took 0.8743165079504251 seconds)
2023-11-04 10:22:02 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-11-04 10:22:02 | INFO | train | epoch 021 | loss 9.105 | nll_loss 8.871 | ppl 468.29 | wps 4633.9 | ups 1.81 | wpb 2560 | bsz 266.7 | num_updates 63 | lr 7.875e-06 | gnorm 2.473 | train_wall 0 | gb_free 45.8 | wall 46
2023-11-04 10:22:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:02 | INFO | fairseq.trainer | begin training epoch 22
2023-11-04 10:22:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:03 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:22:03 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:03 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:22:03 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:03 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.091 | nll_loss 8.813 | ppl 449.62 | bleu 0.47 | wps 855.5 | wpb 573.5 | bsz 50 | num_updates 66 | best_bleu 0.57
2023-11-04 10:22:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 66 updates
2023-11-04 10:22:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 22 @ 66 updates, score 0.47) (writing took 0.8453544732183218 seconds)
2023-11-04 10:22:04 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-11-04 10:22:04 | INFO | train | epoch 022 | loss 9.058 | nll_loss 8.816 | ppl 450.54 | wps 4557.6 | ups 1.78 | wpb 2560 | bsz 266.7 | num_updates 66 | lr 8.25e-06 | gnorm 2.432 | train_wall 0 | gb_free 45.9 | wall 48
2023-11-04 10:22:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:04 | INFO | fairseq.trainer | begin training epoch 23
2023-11-04 10:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:04 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:22:04 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:05 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:22:05 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:05 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.021 | nll_loss 8.737 | ppl 426.77 | bleu 0.48 | wps 944.9 | wpb 573.5 | bsz 50 | num_updates 69 | best_bleu 0.57
2023-11-04 10:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 69 updates
2023-11-04 10:22:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 23 @ 69 updates, score 0.48) (writing took 0.8480700086802244 seconds)
2023-11-04 10:22:05 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-11-04 10:22:05 | INFO | train | epoch 023 | loss 9.041 | nll_loss 8.795 | ppl 444.27 | wps 4786.4 | ups 1.87 | wpb 2560 | bsz 266.7 | num_updates 69 | lr 8.625e-06 | gnorm 2.436 | train_wall 0 | gb_free 45.9 | wall 49
2023-11-04 10:22:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:05 | INFO | fairseq.trainer | begin training epoch 24
2023-11-04 10:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:06 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:06 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:06 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:06 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:06 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.923 | nll_loss 8.636 | ppl 397.78 | bleu 0.44 | wps 864.5 | wpb 573.5 | bsz 50 | num_updates 72 | best_bleu 0.57
2023-11-04 10:22:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 72 updates
2023-11-04 10:22:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 24 @ 72 updates, score 0.44) (writing took 0.8558560740202665 seconds)
2023-11-04 10:22:07 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-11-04 10:22:07 | INFO | train | epoch 024 | loss 8.958 | nll_loss 8.704 | ppl 417.13 | wps 4600.5 | ups 1.8 | wpb 2560 | bsz 266.7 | num_updates 72 | lr 9e-06 | gnorm 2.333 | train_wall 0 | gb_free 45.8 | wall 51
2023-11-04 10:22:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:07 | INFO | fairseq.trainer | begin training epoch 25
2023-11-04 10:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:08 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:08 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:08 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:08 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:08 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.846 | nll_loss 8.555 | ppl 376.19 | bleu 0.44 | wps 789.8 | wpb 573.5 | bsz 50 | num_updates 75 | best_bleu 0.57
2023-11-04 10:22:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 75 updates
2023-11-04 10:22:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 25 @ 75 updates, score 0.44) (writing took 0.8452210072427988 seconds)
2023-11-04 10:22:09 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-11-04 10:22:09 | INFO | train | epoch 025 | loss 8.934 | nll_loss 8.68 | ppl 410.23 | wps 4334 | ups 1.69 | wpb 2560 | bsz 266.7 | num_updates 75 | lr 9.375e-06 | gnorm 2.193 | train_wall 0 | gb_free 45.8 | wall 53
2023-11-04 10:22:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:09 | INFO | fairseq.trainer | begin training epoch 26
2023-11-04 10:22:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:10 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:10 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:10 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:10 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:10 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.787 | nll_loss 8.492 | ppl 359.95 | bleu 0.43 | wps 942.3 | wpb 573.5 | bsz 50 | num_updates 78 | best_bleu 0.57
2023-11-04 10:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 78 updates
2023-11-04 10:22:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 26 @ 78 updates, score 0.43) (writing took 0.8573208451271057 seconds)
2023-11-04 10:22:10 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-11-04 10:22:10 | INFO | train | epoch 026 | loss 8.882 | nll_loss 8.623 | ppl 394.26 | wps 4763.1 | ups 1.86 | wpb 2560 | bsz 266.7 | num_updates 78 | lr 9.75e-06 | gnorm 2.18 | train_wall 0 | gb_free 45.8 | wall 54
2023-11-04 10:22:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:11 | INFO | fairseq.trainer | begin training epoch 27
2023-11-04 10:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:11 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:11 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:11 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:11 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:11 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.754 | nll_loss 8.452 | ppl 350.12 | bleu 0.44 | wps 872.6 | wpb 573.5 | bsz 50 | num_updates 81 | best_bleu 0.57
2023-11-04 10:22:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 81 updates
2023-11-04 10:22:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 27 @ 81 updates, score 0.44) (writing took 0.8628565482795238 seconds)
2023-11-04 10:22:12 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-11-04 10:22:12 | INFO | train | epoch 027 | loss 8.871 | nll_loss 8.61 | ppl 390.8 | wps 4539.1 | ups 1.77 | wpb 2560 | bsz 266.7 | num_updates 81 | lr 1.0125e-05 | gnorm 2.117 | train_wall 0 | gb_free 45.8 | wall 56
2023-11-04 10:22:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:12 | INFO | fairseq.trainer | begin training epoch 28
2023-11-04 10:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:13 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:13 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:13 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:13 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:13 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.722 | nll_loss 8.414 | ppl 341.08 | bleu 0.45 | wps 600.8 | wpb 573.5 | bsz 50 | num_updates 84 | best_bleu 0.57
2023-11-04 10:22:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 84 updates
2023-11-04 10:22:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 28 @ 84 updates, score 0.45) (writing took 0.8800410684198141 seconds)
2023-11-04 10:22:14 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-11-04 10:22:14 | INFO | train | epoch 028 | loss 8.819 | nll_loss 8.551 | ppl 374.99 | wps 4233.3 | ups 1.65 | wpb 2560 | bsz 266.7 | num_updates 84 | lr 1.05e-05 | gnorm 2.15 | train_wall 0 | gb_free 45.8 | wall 58
2023-11-04 10:22:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:14 | INFO | fairseq.trainer | begin training epoch 29
2023-11-04 10:22:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:15 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:15 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:15 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:15 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:15 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.677 | nll_loss 8.364 | ppl 329.57 | bleu 0.45 | wps 943.3 | wpb 573.5 | bsz 50 | num_updates 87 | best_bleu 0.57
2023-11-04 10:22:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 87 updates
2023-11-04 10:22:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 29 @ 87 updates, score 0.45) (writing took 0.911359392106533 seconds)
2023-11-04 10:22:16 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-11-04 10:22:16 | INFO | train | epoch 029 | loss 8.783 | nll_loss 8.509 | ppl 364.3 | wps 4597.6 | ups 1.8 | wpb 2560 | bsz 266.7 | num_updates 87 | lr 1.0875e-05 | gnorm 1.983 | train_wall 0 | gb_free 45.8 | wall 60
2023-11-04 10:22:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:16 | INFO | fairseq.trainer | begin training epoch 30
2023-11-04 10:22:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:16 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:16 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:16 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:16 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:16 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.623 | nll_loss 8.307 | ppl 316.64 | bleu 0.45 | wps 872.7 | wpb 573.5 | bsz 50 | num_updates 90 | best_bleu 0.57
2023-11-04 10:22:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 90 updates
2023-11-04 10:22:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 30 @ 90 updates, score 0.45) (writing took 0.8587407674640417 seconds)
2023-11-04 10:22:17 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-11-04 10:22:17 | INFO | train | epoch 030 | loss 8.762 | nll_loss 8.486 | ppl 358.48 | wps 4554 | ups 1.78 | wpb 2560 | bsz 266.7 | num_updates 90 | lr 1.125e-05 | gnorm 1.929 | train_wall 0 | gb_free 45.9 | wall 61
2023-11-04 10:22:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:17 | INFO | fairseq.trainer | begin training epoch 31
2023-11-04 10:22:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:18 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:18 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:18 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:18 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:18 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.558 | nll_loss 8.239 | ppl 302.22 | bleu 0.46 | wps 945.7 | wpb 573.5 | bsz 50 | num_updates 93 | best_bleu 0.57
2023-11-04 10:22:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 93 updates
2023-11-04 10:22:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 31 @ 93 updates, score 0.46) (writing took 0.8405188862234354 seconds)
2023-11-04 10:22:19 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-11-04 10:22:19 | INFO | train | epoch 031 | loss 8.718 | nll_loss 8.439 | ppl 347.04 | wps 4790.5 | ups 1.87 | wpb 2560 | bsz 266.7 | num_updates 93 | lr 1.1625e-05 | gnorm 1.929 | train_wall 0 | gb_free 45.8 | wall 63
2023-11-04 10:22:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:19 | INFO | fairseq.trainer | begin training epoch 32
2023-11-04 10:22:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:20 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:20 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:20 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:20 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:20 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.506 | nll_loss 8.184 | ppl 290.76 | bleu 0.48 | wps 872.7 | wpb 573.5 | bsz 50 | num_updates 96 | best_bleu 0.57
2023-11-04 10:22:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 96 updates
2023-11-04 10:22:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 32 @ 96 updates, score 0.48) (writing took 0.8788448460400105 seconds)
2023-11-04 10:22:21 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-11-04 10:22:21 | INFO | train | epoch 032 | loss 8.686 | nll_loss 8.404 | ppl 338.75 | wps 4542 | ups 1.77 | wpb 2560 | bsz 266.7 | num_updates 96 | lr 1.2e-05 | gnorm 1.904 | train_wall 0 | gb_free 45.8 | wall 65
2023-11-04 10:22:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:21 | INFO | fairseq.trainer | begin training epoch 33
2023-11-04 10:22:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:21 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:21 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:22 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:22 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:22 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.476 | nll_loss 8.148 | ppl 283.59 | bleu 0.55 | wps 849 | wpb 573.5 | bsz 50 | num_updates 99 | best_bleu 0.57
2023-11-04 10:22:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 99 updates
2023-11-04 10:22:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 33 @ 99 updates, score 0.55) (writing took 0.8487476073205471 seconds)
2023-11-04 10:22:22 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-11-04 10:22:22 | INFO | train | epoch 033 | loss 8.653 | nll_loss 8.367 | ppl 330.19 | wps 4276.3 | ups 1.67 | wpb 2560 | bsz 266.7 | num_updates 99 | lr 1.2375e-05 | gnorm 1.834 | train_wall 0 | gb_free 45.8 | wall 66
2023-11-04 10:22:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:22 | INFO | fairseq.trainer | begin training epoch 34
2023-11-04 10:22:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:23 | INFO | train_inner | epoch 034:      1 / 3 loss=9.485, nll_loss=9.297, ppl=628.89, wps=3892.9, ups=1.52, wpb=2559.6, bsz=267.7, num_updates=100, lr=1.25e-05, gnorm=3.985, train_wall=14, gb_free=45.8, wall=67
2023-11-04 10:22:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:23 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:22:23 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:23 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:22:23 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:23 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.454 | nll_loss 8.119 | ppl 278.05 | bleu 0.65 | wps 947.4 | wpb 573.5 | bsz 50 | num_updates 102 | best_bleu 0.65
2023-11-04 10:22:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 102 updates
2023-11-04 10:22:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:22:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:22:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 34 @ 102 updates, score 0.65) (writing took 1.4041403494775295 seconds)
2023-11-04 10:22:25 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-11-04 10:22:25 | INFO | train | epoch 034 | loss 8.618 | nll_loss 8.325 | ppl 320.78 | wps 3532.7 | ups 1.38 | wpb 2560 | bsz 266.7 | num_updates 102 | lr 1.275e-05 | gnorm 1.854 | train_wall 0 | gb_free 45.8 | wall 68
2023-11-04 10:22:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:25 | INFO | fairseq.trainer | begin training epoch 35
2023-11-04 10:22:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:25 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the
2023-11-04 10:22:25 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:25 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:22:25 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:25 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.408 | nll_loss 8.068 | ppl 268.44 | bleu 0.61 | wps 955.8 | wpb 573.5 | bsz 50 | num_updates 105 | best_bleu 0.65
2023-11-04 10:22:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 105 updates
2023-11-04 10:22:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
2023-11-04 10:22:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt (epoch 35 @ 105 updates, score 0.61) (writing took 0.83712487667799 seconds)
2023-11-04 10:22:26 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-11-04 10:22:26 | INFO | train | epoch 035 | loss 8.588 | nll_loss 8.291 | ppl 313.29 | wps 4796.7 | ups 1.87 | wpb 2560 | bsz 266.7 | num_updates 105 | lr 1.3125e-05 | gnorm 1.773 | train_wall 0 | gb_free 45.8 | wall 70
2023-11-04 10:22:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:26 | INFO | fairseq.trainer | begin training epoch 36
2023-11-04 10:22:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:27 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:22:27 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:27 | INFO | fairseq.tasks.translation | example hypothesis: the the the the
2023-11-04 10:22:27 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:27 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.347 | nll_loss 8.004 | ppl 256.71 | bleu 0.67 | wps 883.7 | wpb 573.5 | bsz 50 | num_updates 108 | best_bleu 0.67
2023-11-04 10:22:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 108 updates
2023-11-04 10:22:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:22:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:22:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 36 @ 108 updates, score 0.67) (writing took 1.4331866055727005 seconds)
2023-11-04 10:22:29 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-11-04 10:22:29 | INFO | train | epoch 036 | loss 8.546 | nll_loss 8.245 | ppl 303.41 | wps 3272.5 | ups 1.28 | wpb 2560 | bsz 266.7 | num_updates 108 | lr 1.35e-05 | gnorm 1.785 | train_wall 0 | gb_free 45.8 | wall 72
2023-11-04 10:22:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:29 | INFO | fairseq.trainer | begin training epoch 37
2023-11-04 10:22:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:29 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:22:29 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:30 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:22:30 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:30 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.303 | nll_loss 7.954 | ppl 247.89 | bleu 1.18 | wps 798.6 | wpb 573.5 | bsz 50 | num_updates 111 | best_bleu 1.18
2023-11-04 10:22:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 111 updates
2023-11-04 10:22:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:22:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:22:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 37 @ 111 updates, score 1.18) (writing took 1.390812361612916 seconds)
2023-11-04 10:22:31 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-11-04 10:22:31 | INFO | train | epoch 037 | loss 8.489 | nll_loss 8.182 | ppl 290.43 | wps 3293.2 | ups 1.29 | wpb 2560 | bsz 266.7 | num_updates 111 | lr 1.3875e-05 | gnorm 1.727 | train_wall 0 | gb_free 45.8 | wall 75
2023-11-04 10:22:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:31 | INFO | fairseq.trainer | begin training epoch 38
2023-11-04 10:22:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:32 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:22:32 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:32 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:22:32 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:32 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.264 | nll_loss 7.906 | ppl 239.92 | bleu 1.53 | wps 900.7 | wpb 573.5 | bsz 50 | num_updates 114 | best_bleu 1.53
2023-11-04 10:22:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 114 updates
2023-11-04 10:22:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:22:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt
2023-11-04 10:22:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_best.pt (epoch 38 @ 114 updates, score 1.53) (writing took 1.4012600760906935 seconds)
2023-11-04 10:22:33 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-11-04 10:22:33 | INFO | train | epoch 038 | loss 8.463 | nll_loss 8.152 | ppl 284.53 | wps 3257.9 | ups 1.27 | wpb 2560 | bsz 266.7 | num_updates 114 | lr 1.425e-05 | gnorm 1.743 | train_wall 0 | gb_free 45.8 | wall 77
2023-11-04 10:22:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3
2023-11-04 10:22:33 | INFO | fairseq.trainer | begin training epoch 39
2023-11-04 10:22:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-11-04 10:22:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-11-04 10:22:34 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:22:34 | INFO | fairseq.tasks.translation | example reference: the hagufidufrumig gluUNKNOWNTOKENINREF flohachalates the bokabamibulir
2023-11-04 10:22:34 | INFO | fairseq.tasks.translation | example hypothesis: the the the
2023-11-04 10:22:34 | INFO | fairseq.tasks.translation | example reference: the flumakidobafat boglakeejubofroxates the lojofrifohijug
2023-11-04 10:22:34 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.215 | nll_loss 7.85 | ppl 230.75 | bleu 1.19 | wps 602.5 | wpb 573.5 | bsz 50 | num_updates 117 | best_bleu 1.53
2023-11-04 10:22:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 117 updates
2023-11-04 10:22:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/storage/jcheigh/testperanto/experiment_pipeline/experiment_data/experiments/svo_permutations/results/SVO_OVS_1.0k/checkpoints/checkpoint_last.pt
